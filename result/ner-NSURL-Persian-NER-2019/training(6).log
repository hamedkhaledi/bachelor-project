2022-05-18 16:58:03,973 ----------------------------------------------------------------------------------------------------
2022-05-18 16:58:03,975 Model: "SequenceTagger(
  (embeddings): TransformerWordEmbeddings(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(100000, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=768, out_features=768, bias=True)
  (rnn): LSTM(768, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=18, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2022-05-18 16:58:03,976 ----------------------------------------------------------------------------------------------------
2022-05-18 16:58:03,976 Corpus: "Corpus: 23060 train + 4070 dev + 4150 test sentences"
2022-05-18 16:58:03,976 ----------------------------------------------------------------------------------------------------
2022-05-18 16:58:03,976 Parameters:
2022-05-18 16:58:03,976  - learning_rate: "5e-06"
2022-05-18 16:58:03,976  - mini_batch_size: "4"
2022-05-18 16:58:03,976  - patience: "3"
2022-05-18 16:58:03,976  - anneal_factor: "0.5"
2022-05-18 16:58:03,976  - max_epochs: "30"
2022-05-18 16:58:03,976  - shuffle: "True"
2022-05-18 16:58:03,976  - train_with_dev: "False"
2022-05-18 16:58:03,977  - batch_growth_annealing: "False"
2022-05-18 16:58:03,977 ----------------------------------------------------------------------------------------------------
2022-05-18 16:58:03,977 Model training base path: "data/ner/model2"
2022-05-18 16:58:03,977 ----------------------------------------------------------------------------------------------------
2022-05-18 16:58:03,977 Device: cuda:0
2022-05-18 16:58:03,977 ----------------------------------------------------------------------------------------------------
2022-05-18 16:58:03,977 Embeddings storage mode: cpu
2022-05-18 16:58:03,978 ----------------------------------------------------------------------------------------------------
2022-05-18 17:01:19,450 epoch 1 - iter 576/5765 - loss 4.05705734 - samples/sec: 11.79 - lr: 0.000000
2022-05-18 17:04:30,561 epoch 1 - iter 1152/5765 - loss 3.91709197 - samples/sec: 12.06 - lr: 0.000000
2022-05-18 17:07:44,666 epoch 1 - iter 1728/5765 - loss 3.57395145 - samples/sec: 11.87 - lr: 0.000000
2022-05-18 17:10:55,515 epoch 1 - iter 2304/5765 - loss 3.15240002 - samples/sec: 12.08 - lr: 0.000001
2022-05-18 17:14:14,837 epoch 1 - iter 2880/5765 - loss 2.72412685 - samples/sec: 11.56 - lr: 0.000001
2022-05-18 17:17:54,449 epoch 1 - iter 3456/5765 - loss 2.33638914 - samples/sec: 10.49 - lr: 0.000001
2022-05-18 17:21:21,289 epoch 1 - iter 4032/5765 - loss 2.07138409 - samples/sec: 11.14 - lr: 0.000001
2022-05-18 17:24:45,382 epoch 1 - iter 4608/5765 - loss 1.88130773 - samples/sec: 11.29 - lr: 0.000001
2022-05-18 17:28:04,260 epoch 1 - iter 5184/5765 - loss 1.74112267 - samples/sec: 11.59 - lr: 0.000001
2022-05-18 17:31:26,685 epoch 1 - iter 5760/5765 - loss 1.61745117 - samples/sec: 11.38 - lr: 0.000002
2022-05-18 17:31:28,595 ----------------------------------------------------------------------------------------------------
2022-05-18 17:31:28,595 EPOCH 1 done: loss 1.6163 - lr 0.0000017
2022-05-18 17:34:09,219 DEV : loss 0.45139259099960327 - f1-score (micro avg)  0.0118
2022-05-18 17:34:09,528 BAD EPOCHS (no improvement): 4
2022-05-18 17:34:09,528 ----------------------------------------------------------------------------------------------------
2022-05-18 17:37:37,987 epoch 2 - iter 576/5765 - loss 0.48889475 - samples/sec: 11.06 - lr: 0.000002
2022-05-18 17:41:10,287 epoch 2 - iter 1152/5765 - loss 0.45751413 - samples/sec: 10.86 - lr: 0.000002
2022-05-18 17:44:38,656 epoch 2 - iter 1728/5765 - loss 0.43815030 - samples/sec: 11.06 - lr: 0.000002
2022-05-18 17:48:05,079 epoch 2 - iter 2304/5765 - loss 0.42205744 - samples/sec: 11.16 - lr: 0.000002
2022-05-18 17:51:30,393 epoch 2 - iter 2880/5765 - loss 0.41168923 - samples/sec: 11.22 - lr: 0.000002
2022-05-18 17:54:59,036 epoch 2 - iter 3456/5765 - loss 0.40188399 - samples/sec: 11.05 - lr: 0.000003
2022-05-18 17:58:27,358 epoch 2 - iter 4032/5765 - loss 0.39091322 - samples/sec: 11.06 - lr: 0.000003
2022-05-18 18:02:05,374 epoch 2 - iter 4608/5765 - loss 0.37765902 - samples/sec: 10.57 - lr: 0.000003
2022-05-18 18:05:45,303 epoch 2 - iter 5184/5765 - loss 0.36529809 - samples/sec: 10.48 - lr: 0.000003
2022-05-18 18:09:18,953 epoch 2 - iter 5760/5765 - loss 0.35367478 - samples/sec: 10.79 - lr: 0.000003
2022-05-18 18:09:20,891 ----------------------------------------------------------------------------------------------------
2022-05-18 18:09:20,892 EPOCH 2 done: loss 0.3536 - lr 0.0000033
2022-05-18 18:12:16,313 DEV : loss 0.2243356555700302 - f1-score (micro avg)  0.4756
2022-05-18 18:12:16,626 BAD EPOCHS (no improvement): 4
2022-05-18 18:12:16,627 ----------------------------------------------------------------------------------------------------
2022-05-18 18:16:14,196 epoch 3 - iter 576/5765 - loss 0.24039336 - samples/sec: 9.70 - lr: 0.000003
2022-05-18 18:20:04,174 epoch 3 - iter 1152/5765 - loss 0.22300482 - samples/sec: 10.02 - lr: 0.000004
2022-05-18 18:23:56,047 epoch 3 - iter 1728/5765 - loss 0.21249330 - samples/sec: 9.94 - lr: 0.000004
2022-05-18 18:28:28,909 epoch 3 - iter 2304/5765 - loss 0.20574793 - samples/sec: 8.45 - lr: 0.000004
2022-05-18 18:32:13,906 epoch 3 - iter 2880/5765 - loss 0.19975415 - samples/sec: 10.24 - lr: 0.000004
2022-05-18 18:36:22,683 epoch 3 - iter 3456/5765 - loss 0.19485164 - samples/sec: 9.26 - lr: 0.000004
2022-05-18 18:40:38,537 epoch 3 - iter 4032/5765 - loss 0.18969810 - samples/sec: 9.01 - lr: 0.000004
2022-05-18 18:45:38,525 epoch 3 - iter 4608/5765 - loss 0.18432160 - samples/sec: 7.68 - lr: 0.000005
2022-05-18 18:50:39,393 epoch 3 - iter 5184/5765 - loss 0.17963487 - samples/sec: 7.66 - lr: 0.000005
2022-05-18 18:55:39,757 epoch 3 - iter 5760/5765 - loss 0.17552460 - samples/sec: 7.67 - lr: 0.000005
2022-05-18 18:55:42,500 ----------------------------------------------------------------------------------------------------
2022-05-18 18:55:42,502 EPOCH 3 done: loss 0.1755 - lr 0.0000050
2022-05-18 18:59:36,598 DEV : loss 0.13748052716255188 - f1-score (micro avg)  0.7185
2022-05-18 18:59:37,014 BAD EPOCHS (no improvement): 4
2022-05-18 18:59:37,014 ----------------------------------------------------------------------------------------------------
2022-05-18 19:04:36,590 epoch 4 - iter 576/5765 - loss 0.11723560 - samples/sec: 7.69 - lr: 0.000005
2022-05-18 19:08:43,368 epoch 4 - iter 1152/5765 - loss 0.12181171 - samples/sec: 9.34 - lr: 0.000005
2022-05-18 19:12:46,254 epoch 4 - iter 1728/5765 - loss 0.11914761 - samples/sec: 9.49 - lr: 0.000005
2022-05-18 19:16:44,278 epoch 4 - iter 2304/5765 - loss 0.11761424 - samples/sec: 9.68 - lr: 0.000005
2022-05-18 19:20:24,595 epoch 4 - iter 2880/5765 - loss 0.11663333 - samples/sec: 10.46 - lr: 0.000005
2022-05-18 19:24:04,620 epoch 4 - iter 3456/5765 - loss 0.11560991 - samples/sec: 10.47 - lr: 0.000005
2022-05-18 19:27:47,965 epoch 4 - iter 4032/5765 - loss 0.11334200 - samples/sec: 10.32 - lr: 0.000005
2022-05-18 19:31:27,035 epoch 4 - iter 4608/5765 - loss 0.11234520 - samples/sec: 10.52 - lr: 0.000005
2022-05-18 19:35:06,285 epoch 4 - iter 5184/5765 - loss 0.11023713 - samples/sec: 10.51 - lr: 0.000005
2022-05-18 19:38:55,076 epoch 4 - iter 5760/5765 - loss 0.10922112 - samples/sec: 10.07 - lr: 0.000005
2022-05-18 19:38:56,999 ----------------------------------------------------------------------------------------------------
2022-05-18 19:38:57,000 EPOCH 4 done: loss 0.1092 - lr 0.0000048
2022-05-18 19:41:42,152 DEV : loss 0.1189785897731781 - f1-score (micro avg)  0.7985
2022-05-18 19:41:42,524 BAD EPOCHS (no improvement): 4
2022-05-18 19:41:42,525 ----------------------------------------------------------------------------------------------------
2022-05-18 19:45:23,461 epoch 5 - iter 576/5765 - loss 0.08346560 - samples/sec: 10.43 - lr: 0.000005
2022-05-18 19:49:02,922 epoch 5 - iter 1152/5765 - loss 0.08250486 - samples/sec: 10.50 - lr: 0.000005
2022-05-18 19:52:48,796 epoch 5 - iter 1728/5765 - loss 0.08116751 - samples/sec: 10.20 - lr: 0.000005
2022-05-18 19:56:29,373 epoch 5 - iter 2304/5765 - loss 0.08136082 - samples/sec: 10.45 - lr: 0.000005
2022-05-18 20:00:07,136 epoch 5 - iter 2880/5765 - loss 0.07993380 - samples/sec: 10.58 - lr: 0.000005
2022-05-18 20:03:49,210 epoch 5 - iter 3456/5765 - loss 0.08066864 - samples/sec: 10.38 - lr: 0.000005
2022-05-18 20:07:30,431 epoch 5 - iter 4032/5765 - loss 0.08044388 - samples/sec: 10.42 - lr: 0.000005
2022-05-18 20:11:06,415 epoch 5 - iter 4608/5765 - loss 0.08076605 - samples/sec: 10.67 - lr: 0.000005
2022-05-18 20:14:49,704 epoch 5 - iter 5184/5765 - loss 0.08062739 - samples/sec: 10.32 - lr: 0.000005
2022-05-18 20:18:27,645 epoch 5 - iter 5760/5765 - loss 0.08048465 - samples/sec: 10.57 - lr: 0.000005
2022-05-18 20:18:29,468 ----------------------------------------------------------------------------------------------------
2022-05-18 20:18:29,469 EPOCH 5 done: loss 0.0804 - lr 0.0000046
2022-05-18 20:21:15,712 DEV : loss 0.11298475414514542 - f1-score (micro avg)  0.821
2022-05-18 20:21:16,025 BAD EPOCHS (no improvement): 4
2022-05-18 20:21:16,025 ----------------------------------------------------------------------------------------------------
2022-05-18 20:24:51,751 epoch 6 - iter 576/5765 - loss 0.06723396 - samples/sec: 10.68 - lr: 0.000005
2022-05-18 20:28:32,294 epoch 6 - iter 1152/5765 - loss 0.06405478 - samples/sec: 10.45 - lr: 0.000005
2022-05-18 20:32:11,986 epoch 6 - iter 1728/5765 - loss 0.06491575 - samples/sec: 10.49 - lr: 0.000005
2022-05-18 20:35:51,514 epoch 6 - iter 2304/5765 - loss 0.06440993 - samples/sec: 10.50 - lr: 0.000005
2022-05-18 20:39:33,922 epoch 6 - iter 2880/5765 - loss 0.06348652 - samples/sec: 10.36 - lr: 0.000005
2022-05-18 20:43:12,223 epoch 6 - iter 3456/5765 - loss 0.06327604 - samples/sec: 10.56 - lr: 0.000005
2022-05-18 20:46:51,123 epoch 6 - iter 4032/5765 - loss 0.06327705 - samples/sec: 10.53 - lr: 0.000005
2022-05-18 20:50:32,012 epoch 6 - iter 4608/5765 - loss 0.06253846 - samples/sec: 10.43 - lr: 0.000004
2022-05-18 20:54:11,716 epoch 6 - iter 5184/5765 - loss 0.06261716 - samples/sec: 10.49 - lr: 0.000004
2022-05-18 20:57:54,973 epoch 6 - iter 5760/5765 - loss 0.06327731 - samples/sec: 10.32 - lr: 0.000004
2022-05-18 20:57:56,786 ----------------------------------------------------------------------------------------------------
2022-05-18 20:57:56,787 EPOCH 6 done: loss 0.0633 - lr 0.0000044
2022-05-18 21:00:46,705 DEV : loss 0.12577219307422638 - f1-score (micro avg)  0.8262
2022-05-18 21:00:47,007 BAD EPOCHS (no improvement): 4
2022-05-18 21:00:47,007 ----------------------------------------------------------------------------------------------------
2022-05-18 21:04:34,341 epoch 7 - iter 576/5765 - loss 0.05607352 - samples/sec: 10.14 - lr: 0.000004
2022-05-18 21:08:15,986 epoch 7 - iter 1152/5765 - loss 0.05730540 - samples/sec: 10.40 - lr: 0.000004
2022-05-18 21:11:54,687 epoch 7 - iter 1728/5765 - loss 0.05475601 - samples/sec: 10.54 - lr: 0.000004
2022-05-18 21:15:41,216 epoch 7 - iter 2304/5765 - loss 0.05469290 - samples/sec: 10.17 - lr: 0.000004
2022-05-18 21:19:19,103 epoch 7 - iter 2880/5765 - loss 0.05453390 - samples/sec: 10.58 - lr: 0.000004
2022-05-18 21:23:01,377 epoch 7 - iter 3456/5765 - loss 0.05326938 - samples/sec: 10.37 - lr: 0.000004
2022-05-18 21:26:42,305 epoch 7 - iter 4032/5765 - loss 0.05285929 - samples/sec: 10.43 - lr: 0.000004
2022-05-18 21:30:26,687 epoch 7 - iter 4608/5765 - loss 0.05295562 - samples/sec: 10.27 - lr: 0.000004
2022-05-18 21:34:07,783 epoch 7 - iter 5184/5765 - loss 0.05324066 - samples/sec: 10.42 - lr: 0.000004
2022-05-18 21:37:55,996 epoch 7 - iter 5760/5765 - loss 0.05296743 - samples/sec: 10.10 - lr: 0.000004
2022-05-18 21:37:57,677 ----------------------------------------------------------------------------------------------------
2022-05-18 21:37:57,677 EPOCH 7 done: loss 0.0530 - lr 0.0000043
2022-05-18 21:40:47,448 DEV : loss 0.1526106894016266 - f1-score (micro avg)  0.8283
2022-05-18 21:40:47,793 BAD EPOCHS (no improvement): 4
2022-05-18 21:40:47,794 ----------------------------------------------------------------------------------------------------
2022-05-18 21:44:31,485 epoch 8 - iter 576/5765 - loss 0.05100049 - samples/sec: 10.30 - lr: 0.000004
2022-05-18 21:48:13,574 epoch 8 - iter 1152/5765 - loss 0.04587791 - samples/sec: 10.38 - lr: 0.000004
2022-05-18 21:51:58,716 epoch 8 - iter 1728/5765 - loss 0.04515852 - samples/sec: 10.24 - lr: 0.000004
2022-05-18 21:55:41,134 epoch 8 - iter 2304/5765 - loss 0.04513654 - samples/sec: 10.36 - lr: 0.000004
2022-05-18 21:59:23,562 epoch 8 - iter 2880/5765 - loss 0.04455299 - samples/sec: 10.36 - lr: 0.000004
2022-05-18 22:03:09,244 epoch 8 - iter 3456/5765 - loss 0.04520794 - samples/sec: 10.21 - lr: 0.000004
2022-05-18 22:06:53,720 epoch 8 - iter 4032/5765 - loss 0.04498828 - samples/sec: 10.27 - lr: 0.000004
2022-05-18 22:10:35,693 epoch 8 - iter 4608/5765 - loss 0.04510136 - samples/sec: 10.38 - lr: 0.000004
2022-05-18 22:14:16,419 epoch 8 - iter 5184/5765 - loss 0.04506086 - samples/sec: 10.44 - lr: 0.000004
2022-05-18 22:17:59,938 epoch 8 - iter 5760/5765 - loss 0.04540659 - samples/sec: 10.31 - lr: 0.000004
2022-05-18 22:18:01,794 ----------------------------------------------------------------------------------------------------
2022-05-18 22:18:01,795 EPOCH 8 done: loss 0.0454 - lr 0.0000041
2022-05-18 22:20:51,146 DEV : loss 0.16176970303058624 - f1-score (micro avg)  0.8304
2022-05-18 22:20:51,445 BAD EPOCHS (no improvement): 4
2022-05-18 22:20:51,445 ----------------------------------------------------------------------------------------------------
2022-05-18 22:24:27,324 epoch 9 - iter 576/5765 - loss 0.03775664 - samples/sec: 10.68 - lr: 0.000004
2022-05-18 22:28:05,913 epoch 9 - iter 1152/5765 - loss 0.03753836 - samples/sec: 10.54 - lr: 0.000004
2022-05-18 22:31:47,012 epoch 9 - iter 1728/5765 - loss 0.03680293 - samples/sec: 10.42 - lr: 0.000004
2022-05-18 22:35:29,936 epoch 9 - iter 2304/5765 - loss 0.03739642 - samples/sec: 10.34 - lr: 0.000004
2022-05-18 22:39:07,540 epoch 9 - iter 2880/5765 - loss 0.03710986 - samples/sec: 10.59 - lr: 0.000004
2022-05-18 22:42:50,939 epoch 9 - iter 3456/5765 - loss 0.03798939 - samples/sec: 10.32 - lr: 0.000004
2022-05-18 22:46:30,663 epoch 9 - iter 4032/5765 - loss 0.03791147 - samples/sec: 10.49 - lr: 0.000004
2022-05-18 22:50:14,456 epoch 9 - iter 4608/5765 - loss 0.03793888 - samples/sec: 10.30 - lr: 0.000004
2022-05-18 22:53:53,694 epoch 9 - iter 5184/5765 - loss 0.03856875 - samples/sec: 10.51 - lr: 0.000004
2022-05-18 22:57:31,383 epoch 9 - iter 5760/5765 - loss 0.03847243 - samples/sec: 10.59 - lr: 0.000004
2022-05-18 22:57:33,323 ----------------------------------------------------------------------------------------------------
2022-05-18 22:57:33,325 EPOCH 9 done: loss 0.0385 - lr 0.0000039
2022-05-18 23:00:16,921 DEV : loss 0.16583247482776642 - f1-score (micro avg)  0.8282
2022-05-18 23:00:17,262 BAD EPOCHS (no improvement): 4
2022-05-18 23:00:17,263 ----------------------------------------------------------------------------------------------------
2022-05-18 23:03:57,268 epoch 10 - iter 576/5765 - loss 0.03621069 - samples/sec: 10.48 - lr: 0.000004
2022-05-18 23:07:41,106 epoch 10 - iter 1152/5765 - loss 0.03531898 - samples/sec: 10.30 - lr: 0.000004
2022-05-18 23:11:21,979 epoch 10 - iter 1728/5765 - loss 0.03482295 - samples/sec: 10.43 - lr: 0.000004
2022-05-18 23:15:03,693 epoch 10 - iter 2304/5765 - loss 0.03564415 - samples/sec: 10.39 - lr: 0.000004
2022-05-18 23:18:40,551 epoch 10 - iter 2880/5765 - loss 0.03508114 - samples/sec: 10.63 - lr: 0.000004
2022-05-18 23:22:15,921 epoch 10 - iter 3456/5765 - loss 0.03502535 - samples/sec: 10.70 - lr: 0.000004
2022-05-18 23:25:57,661 epoch 10 - iter 4032/5765 - loss 0.03514800 - samples/sec: 10.39 - lr: 0.000004
2022-05-18 23:29:38,729 epoch 10 - iter 4608/5765 - loss 0.03505474 - samples/sec: 10.42 - lr: 0.000004
2022-05-18 23:33:17,738 epoch 10 - iter 5184/5765 - loss 0.03521934 - samples/sec: 10.52 - lr: 0.000004
2022-05-18 23:37:03,855 epoch 10 - iter 5760/5765 - loss 0.03530342 - samples/sec: 10.19 - lr: 0.000004
2022-05-18 23:37:05,643 ----------------------------------------------------------------------------------------------------
2022-05-18 23:37:05,644 EPOCH 10 done: loss 0.0353 - lr 0.0000037
2022-05-18 23:39:55,118 DEV : loss 0.1781640499830246 - f1-score (micro avg)  0.8348
2022-05-18 23:39:55,427 BAD EPOCHS (no improvement): 4
2022-05-18 23:39:55,428 ----------------------------------------------------------------------------------------------------
2022-05-18 23:43:39,649 epoch 11 - iter 576/5765 - loss 0.02620366 - samples/sec: 10.28 - lr: 0.000004
2022-05-18 23:47:25,490 epoch 11 - iter 1152/5765 - loss 0.02716774 - samples/sec: 10.20 - lr: 0.000004
2022-05-18 23:51:08,865 epoch 11 - iter 1728/5765 - loss 0.02909793 - samples/sec: 10.32 - lr: 0.000004
2022-05-18 23:54:53,356 epoch 11 - iter 2304/5765 - loss 0.02918325 - samples/sec: 10.27 - lr: 0.000004
2022-05-18 23:58:38,593 epoch 11 - iter 2880/5765 - loss 0.02935322 - samples/sec: 10.23 - lr: 0.000004
2022-05-19 00:02:21,289 epoch 11 - iter 3456/5765 - loss 0.02909111 - samples/sec: 10.35 - lr: 0.000004
2022-05-19 00:06:04,128 epoch 11 - iter 4032/5765 - loss 0.02910860 - samples/sec: 10.34 - lr: 0.000004
2022-05-19 00:09:50,191 epoch 11 - iter 4608/5765 - loss 0.02978128 - samples/sec: 10.20 - lr: 0.000004
2022-05-19 00:13:34,382 epoch 11 - iter 5184/5765 - loss 0.03101261 - samples/sec: 10.28 - lr: 0.000004
2022-05-19 00:17:25,174 epoch 11 - iter 5760/5765 - loss 0.03095297 - samples/sec: 9.99 - lr: 0.000004
2022-05-19 00:17:27,053 ----------------------------------------------------------------------------------------------------
2022-05-19 00:17:27,054 EPOCH 11 done: loss 0.0309 - lr 0.0000035
2022-05-19 00:20:12,485 DEV : loss 0.18210086226463318 - f1-score (micro avg)  0.8358
2022-05-19 00:20:12,800 BAD EPOCHS (no improvement): 4
2022-05-19 00:20:12,801 ----------------------------------------------------------------------------------------------------
2022-05-19 00:23:51,810 epoch 12 - iter 576/5765 - loss 0.02156828 - samples/sec: 10.52 - lr: 0.000004
2022-05-19 00:27:32,695 epoch 12 - iter 1152/5765 - loss 0.02416280 - samples/sec: 10.43 - lr: 0.000003
2022-05-19 00:31:13,172 epoch 12 - iter 1728/5765 - loss 0.02390893 - samples/sec: 10.45 - lr: 0.000003
2022-05-19 00:34:56,769 epoch 12 - iter 2304/5765 - loss 0.02425517 - samples/sec: 10.31 - lr: 0.000003
2022-05-19 00:38:37,844 epoch 12 - iter 2880/5765 - loss 0.02560534 - samples/sec: 10.42 - lr: 0.000003
2022-05-19 00:42:21,335 epoch 12 - iter 3456/5765 - loss 0.02532265 - samples/sec: 10.31 - lr: 0.000003
2022-05-19 00:46:00,068 epoch 12 - iter 4032/5765 - loss 0.02549613 - samples/sec: 10.54 - lr: 0.000003
2022-05-19 00:49:35,134 epoch 12 - iter 4608/5765 - loss 0.02619242 - samples/sec: 10.72 - lr: 0.000003
2022-05-19 00:53:18,647 epoch 12 - iter 5184/5765 - loss 0.02624613 - samples/sec: 10.31 - lr: 0.000003
2022-05-19 00:56:59,772 epoch 12 - iter 5760/5765 - loss 0.02592815 - samples/sec: 10.42 - lr: 0.000003
2022-05-19 00:57:01,684 ----------------------------------------------------------------------------------------------------
2022-05-19 00:57:01,685 EPOCH 12 done: loss 0.0259 - lr 0.0000033
2022-05-19 00:59:52,434 DEV : loss 0.19391131401062012 - f1-score (micro avg)  0.8335
2022-05-19 00:59:52,797 BAD EPOCHS (no improvement): 4
2022-05-19 00:59:52,798 ----------------------------------------------------------------------------------------------------
2022-05-19 01:03:33,742 epoch 13 - iter 576/5765 - loss 0.02209556 - samples/sec: 10.43 - lr: 0.000003
2022-05-19 01:07:17,645 epoch 13 - iter 1152/5765 - loss 0.02475195 - samples/sec: 10.29 - lr: 0.000003
2022-05-19 01:11:00,245 epoch 13 - iter 1728/5765 - loss 0.02516338 - samples/sec: 10.35 - lr: 0.000003
2022-05-19 01:14:39,655 epoch 13 - iter 2304/5765 - loss 0.02403419 - samples/sec: 10.50 - lr: 0.000003
2022-05-19 01:18:21,908 epoch 13 - iter 2880/5765 - loss 0.02336521 - samples/sec: 10.37 - lr: 0.000003
2022-05-19 01:22:04,901 epoch 13 - iter 3456/5765 - loss 0.02380501 - samples/sec: 10.33 - lr: 0.000003
2022-05-19 01:25:48,890 epoch 13 - iter 4032/5765 - loss 0.02402873 - samples/sec: 10.29 - lr: 0.000003
2022-05-19 01:29:30,904 epoch 13 - iter 4608/5765 - loss 0.02455251 - samples/sec: 10.38 - lr: 0.000003
2022-05-19 01:33:11,389 epoch 13 - iter 5184/5765 - loss 0.02444183 - samples/sec: 10.45 - lr: 0.000003
2022-05-19 01:36:53,088 epoch 13 - iter 5760/5765 - loss 0.02413455 - samples/sec: 10.39 - lr: 0.000003
2022-05-19 01:36:55,274 ----------------------------------------------------------------------------------------------------
2022-05-19 01:36:55,276 EPOCH 13 done: loss 0.0241 - lr 0.0000031
2022-05-19 01:39:46,436 DEV : loss 0.2021864652633667 - f1-score (micro avg)  0.8325
2022-05-19 01:39:46,779 BAD EPOCHS (no improvement): 4
2022-05-19 01:39:46,779 ----------------------------------------------------------------------------------------------------
2022-05-19 01:43:27,420 epoch 14 - iter 576/5765 - loss 0.02053999 - samples/sec: 10.45 - lr: 0.000003
2022-05-19 01:47:09,007 epoch 14 - iter 1152/5765 - loss 0.02118579 - samples/sec: 10.40 - lr: 0.000003
2022-05-19 01:50:59,358 epoch 14 - iter 1728/5765 - loss 0.02170557 - samples/sec: 10.00 - lr: 0.000003
2022-05-19 01:54:43,682 epoch 14 - iter 2304/5765 - loss 0.02167460 - samples/sec: 10.27 - lr: 0.000003
2022-05-19 01:58:28,124 epoch 14 - iter 2880/5765 - loss 0.02172500 - samples/sec: 10.27 - lr: 0.000003
2022-05-19 02:02:13,410 epoch 14 - iter 3456/5765 - loss 0.02120848 - samples/sec: 10.23 - lr: 0.000003
2022-05-19 02:05:58,362 epoch 14 - iter 4032/5765 - loss 0.02127843 - samples/sec: 10.24 - lr: 0.000003
2022-05-19 02:09:40,679 epoch 14 - iter 4608/5765 - loss 0.02128953 - samples/sec: 10.37 - lr: 0.000003
2022-05-19 02:13:23,196 epoch 14 - iter 5184/5765 - loss 0.02102960 - samples/sec: 10.36 - lr: 0.000003
2022-05-19 02:17:05,814 epoch 14 - iter 5760/5765 - loss 0.02130503 - samples/sec: 10.35 - lr: 0.000003
2022-05-19 02:17:07,872 ----------------------------------------------------------------------------------------------------
2022-05-19 02:17:07,874 EPOCH 14 done: loss 0.0213 - lr 0.0000030
2022-05-19 02:19:58,777 DEV : loss 0.2046680748462677 - f1-score (micro avg)  0.836
2022-05-19 02:19:59,098 BAD EPOCHS (no improvement): 4
2022-05-19 02:19:59,098 ----------------------------------------------------------------------------------------------------
2022-05-19 02:23:38,734 epoch 15 - iter 576/5765 - loss 0.02009202 - samples/sec: 10.49 - lr: 0.000003
2022-05-19 02:27:19,415 epoch 15 - iter 1152/5765 - loss 0.01846476 - samples/sec: 10.44 - lr: 0.000003
2022-05-19 02:30:55,766 epoch 15 - iter 1728/5765 - loss 0.01925387 - samples/sec: 10.65 - lr: 0.000003
2022-05-19 02:34:36,037 epoch 15 - iter 2304/5765 - loss 0.01971246 - samples/sec: 10.46 - lr: 0.000003
2022-05-19 02:38:18,377 epoch 15 - iter 2880/5765 - loss 0.01972630 - samples/sec: 10.37 - lr: 0.000003
2022-05-19 02:42:03,215 epoch 15 - iter 3456/5765 - loss 0.01947760 - samples/sec: 10.25 - lr: 0.000003
2022-05-19 02:45:51,743 epoch 15 - iter 4032/5765 - loss 0.01928387 - samples/sec: 10.08 - lr: 0.000003
2022-05-19 02:49:32,107 epoch 15 - iter 4608/5765 - loss 0.01917898 - samples/sec: 10.46 - lr: 0.000003
2022-05-19 02:53:08,492 epoch 15 - iter 5184/5765 - loss 0.01961356 - samples/sec: 10.65 - lr: 0.000003
2022-05-19 02:56:49,604 epoch 15 - iter 5760/5765 - loss 0.01981891 - samples/sec: 10.42 - lr: 0.000003
2022-05-19 02:56:51,517 ----------------------------------------------------------------------------------------------------
2022-05-19 02:56:51,518 EPOCH 15 done: loss 0.0198 - lr 0.0000028
2022-05-19 02:59:42,616 DEV : loss 0.20366814732551575 - f1-score (micro avg)  0.8384
2022-05-19 02:59:42,952 BAD EPOCHS (no improvement): 4
2022-05-19 02:59:42,952 ----------------------------------------------------------------------------------------------------
2022-05-19 03:03:26,770 epoch 16 - iter 576/5765 - loss 0.01989935 - samples/sec: 10.30 - lr: 0.000003
2022-05-19 03:07:06,216 epoch 16 - iter 1152/5765 - loss 0.01613399 - samples/sec: 10.50 - lr: 0.000003
2022-05-19 03:10:43,538 epoch 16 - iter 1728/5765 - loss 0.01659399 - samples/sec: 10.60 - lr: 0.000003
2022-05-19 03:14:24,832 epoch 16 - iter 2304/5765 - loss 0.01622303 - samples/sec: 10.41 - lr: 0.000003
2022-05-19 03:18:05,479 epoch 16 - iter 2880/5765 - loss 0.01629010 - samples/sec: 10.44 - lr: 0.000003
2022-05-19 03:21:48,231 epoch 16 - iter 3456/5765 - loss 0.01709038 - samples/sec: 10.35 - lr: 0.000003
2022-05-19 03:25:38,799 epoch 16 - iter 4032/5765 - loss 0.01688499 - samples/sec: 10.00 - lr: 0.000003
2022-05-19 03:29:20,645 epoch 16 - iter 4608/5765 - loss 0.01716572 - samples/sec: 10.39 - lr: 0.000003
2022-05-19 03:32:57,822 epoch 16 - iter 5184/5765 - loss 0.01673290 - samples/sec: 10.61 - lr: 0.000003
2022-05-19 03:36:38,118 epoch 16 - iter 5760/5765 - loss 0.01705861 - samples/sec: 10.46 - lr: 0.000003
2022-05-19 03:36:39,971 ----------------------------------------------------------------------------------------------------
2022-05-19 03:36:39,972 EPOCH 16 done: loss 0.0170 - lr 0.0000026
2022-05-19 03:39:28,164 DEV : loss 0.21461263298988342 - f1-score (micro avg)  0.8349
2022-05-19 03:39:28,511 BAD EPOCHS (no improvement): 4
2022-05-19 03:39:28,511 ----------------------------------------------------------------------------------------------------
2022-05-19 03:43:15,623 epoch 17 - iter 576/5765 - loss 0.01407557 - samples/sec: 10.15 - lr: 0.000003
2022-05-19 03:46:53,089 epoch 17 - iter 1152/5765 - loss 0.01512905 - samples/sec: 10.60 - lr: 0.000003
2022-05-19 03:50:36,573 epoch 17 - iter 1728/5765 - loss 0.01415453 - samples/sec: 10.31 - lr: 0.000003
2022-05-19 03:54:18,580 epoch 17 - iter 2304/5765 - loss 0.01449145 - samples/sec: 10.38 - lr: 0.000003
2022-05-19 03:57:57,474 epoch 17 - iter 2880/5765 - loss 0.01457567 - samples/sec: 10.53 - lr: 0.000003
2022-05-19 04:01:41,399 epoch 17 - iter 3456/5765 - loss 0.01464201 - samples/sec: 10.29 - lr: 0.000002
2022-05-19 04:05:21,574 epoch 17 - iter 4032/5765 - loss 0.01455023 - samples/sec: 10.47 - lr: 0.000002
2022-05-19 04:08:58,279 epoch 17 - iter 4608/5765 - loss 0.01481021 - samples/sec: 10.63 - lr: 0.000002
2022-05-19 04:12:32,054 epoch 17 - iter 5184/5765 - loss 0.01512673 - samples/sec: 10.78 - lr: 0.000002
2022-05-19 04:16:09,232 epoch 17 - iter 5760/5765 - loss 0.01565666 - samples/sec: 10.61 - lr: 0.000002
2022-05-19 04:16:11,127 ----------------------------------------------------------------------------------------------------
2022-05-19 04:16:11,128 EPOCH 17 done: loss 0.0157 - lr 0.0000024
2022-05-19 04:18:56,149 DEV : loss 0.21023227274417877 - f1-score (micro avg)  0.8368
2022-05-19 04:18:56,495 BAD EPOCHS (no improvement): 4
2022-05-19 04:18:56,496 ----------------------------------------------------------------------------------------------------
2022-05-19 04:22:35,820 epoch 18 - iter 576/5765 - loss 0.01278245 - samples/sec: 10.51 - lr: 0.000002
2022-05-19 04:26:10,202 epoch 18 - iter 1152/5765 - loss 0.01301093 - samples/sec: 10.75 - lr: 0.000002
2022-05-19 04:29:51,004 epoch 18 - iter 1728/5765 - loss 0.01380301 - samples/sec: 10.44 - lr: 0.000002
2022-05-19 04:33:35,511 epoch 18 - iter 2304/5765 - loss 0.01349230 - samples/sec: 10.27 - lr: 0.000002
2022-05-19 04:37:16,356 epoch 18 - iter 2880/5765 - loss 0.01395223 - samples/sec: 10.44 - lr: 0.000002
2022-05-19 04:40:58,305 epoch 18 - iter 3456/5765 - loss 0.01363761 - samples/sec: 10.38 - lr: 0.000002
2022-05-19 04:44:42,192 epoch 18 - iter 4032/5765 - loss 0.01358937 - samples/sec: 10.29 - lr: 0.000002
2022-05-19 04:48:23,876 epoch 18 - iter 4608/5765 - loss 0.01374356 - samples/sec: 10.40 - lr: 0.000002
2022-05-19 04:52:05,562 epoch 18 - iter 5184/5765 - loss 0.01380547 - samples/sec: 10.40 - lr: 0.000002
2022-05-19 04:55:49,461 epoch 18 - iter 5760/5765 - loss 0.01392248 - samples/sec: 10.29 - lr: 0.000002
2022-05-19 04:55:51,288 ----------------------------------------------------------------------------------------------------
2022-05-19 04:55:51,288 EPOCH 18 done: loss 0.0139 - lr 0.0000022
2022-05-19 04:58:38,319 DEV : loss 0.22320638597011566 - f1-score (micro avg)  0.8369
2022-05-19 04:58:38,640 BAD EPOCHS (no improvement): 4
2022-05-19 04:58:38,640 ----------------------------------------------------------------------------------------------------
2022-05-19 05:02:19,092 epoch 19 - iter 576/5765 - loss 0.01264376 - samples/sec: 10.45 - lr: 0.000002
2022-05-19 05:06:02,409 epoch 19 - iter 1152/5765 - loss 0.01244688 - samples/sec: 10.32 - lr: 0.000002
2022-05-19 05:09:54,878 epoch 19 - iter 1728/5765 - loss 0.01290834 - samples/sec: 9.91 - lr: 0.000002
2022-05-19 05:13:37,062 epoch 19 - iter 2304/5765 - loss 0.01258492 - samples/sec: 10.37 - lr: 0.000002
2022-05-19 05:17:21,650 epoch 19 - iter 2880/5765 - loss 0.01173421 - samples/sec: 10.26 - lr: 0.000002
2022-05-19 05:21:04,512 epoch 19 - iter 3456/5765 - loss 0.01133173 - samples/sec: 10.34 - lr: 0.000002
2022-05-19 05:24:44,123 epoch 19 - iter 4032/5765 - loss 0.01184309 - samples/sec: 10.49 - lr: 0.000002
2022-05-19 05:28:26,748 epoch 19 - iter 4608/5765 - loss 0.01209853 - samples/sec: 10.35 - lr: 0.000002
2022-05-19 05:32:12,486 epoch 19 - iter 5184/5765 - loss 0.01213832 - samples/sec: 10.21 - lr: 0.000002
2022-05-19 05:35:58,798 epoch 19 - iter 5760/5765 - loss 0.01287967 - samples/sec: 10.18 - lr: 0.000002
2022-05-19 05:36:00,985 ----------------------------------------------------------------------------------------------------
2022-05-19 05:36:00,986 EPOCH 19 done: loss 0.0129 - lr 0.0000020
2022-05-19 05:38:50,065 DEV : loss 0.22605732083320618 - f1-score (micro avg)  0.8403
2022-05-19 05:38:50,396 BAD EPOCHS (no improvement): 4
2022-05-19 05:38:50,397 ----------------------------------------------------------------------------------------------------
2022-05-19 05:42:33,728 epoch 20 - iter 576/5765 - loss 0.00993535 - samples/sec: 10.32 - lr: 0.000002
2022-05-19 05:46:17,147 epoch 20 - iter 1152/5765 - loss 0.01057677 - samples/sec: 10.32 - lr: 0.000002
2022-05-19 05:50:00,791 epoch 20 - iter 1728/5765 - loss 0.01082452 - samples/sec: 10.30 - lr: 0.000002
2022-05-19 05:53:45,567 epoch 20 - iter 2304/5765 - loss 0.01135283 - samples/sec: 10.25 - lr: 0.000002
2022-05-19 05:57:24,334 epoch 20 - iter 2880/5765 - loss 0.01126301 - samples/sec: 10.53 - lr: 0.000002
2022-05-19 06:01:06,751 epoch 20 - iter 3456/5765 - loss 0.01083233 - samples/sec: 10.36 - lr: 0.000002
2022-05-19 06:04:47,866 epoch 20 - iter 4032/5765 - loss 0.01079068 - samples/sec: 10.42 - lr: 0.000002
2022-05-19 06:08:33,052 epoch 20 - iter 4608/5765 - loss 0.01103807 - samples/sec: 10.23 - lr: 0.000002
2022-05-19 06:12:15,682 epoch 20 - iter 5184/5765 - loss 0.01108784 - samples/sec: 10.35 - lr: 0.000002
2022-05-19 06:15:59,410 epoch 20 - iter 5760/5765 - loss 0.01118233 - samples/sec: 10.30 - lr: 0.000002
2022-05-19 06:16:01,266 ----------------------------------------------------------------------------------------------------
2022-05-19 06:16:01,267 EPOCH 20 done: loss 0.0112 - lr 0.0000019
2022-05-19 06:18:52,386 DEV : loss 0.23214831948280334 - f1-score (micro avg)  0.8408
2022-05-19 06:18:52,714 BAD EPOCHS (no improvement): 4
2022-05-19 06:18:52,715 ----------------------------------------------------------------------------------------------------
2022-05-19 06:22:32,009 epoch 21 - iter 576/5765 - loss 0.00837901 - samples/sec: 10.51 - lr: 0.000002
2022-05-19 06:26:13,431 epoch 21 - iter 1152/5765 - loss 0.00803865 - samples/sec: 10.41 - lr: 0.000002
2022-05-19 06:29:57,846 epoch 21 - iter 1728/5765 - loss 0.00866770 - samples/sec: 10.27 - lr: 0.000002
2022-05-19 06:33:43,173 epoch 21 - iter 2304/5765 - loss 0.00919160 - samples/sec: 10.23 - lr: 0.000002
2022-05-19 06:37:26,836 epoch 21 - iter 2880/5765 - loss 0.00950033 - samples/sec: 10.30 - lr: 0.000002
2022-05-19 06:41:14,324 epoch 21 - iter 3456/5765 - loss 0.01003940 - samples/sec: 10.13 - lr: 0.000002
2022-05-19 06:44:54,985 epoch 21 - iter 4032/5765 - loss 0.01019112 - samples/sec: 10.44 - lr: 0.000002
2022-05-19 06:48:45,092 epoch 21 - iter 4608/5765 - loss 0.01054805 - samples/sec: 10.02 - lr: 0.000002
2022-05-19 06:52:26,710 epoch 21 - iter 5184/5765 - loss 0.01052199 - samples/sec: 10.40 - lr: 0.000002
2022-05-19 06:56:13,074 epoch 21 - iter 5760/5765 - loss 0.01035369 - samples/sec: 10.18 - lr: 0.000002
2022-05-19 06:56:14,898 ----------------------------------------------------------------------------------------------------
2022-05-19 06:56:14,898 EPOCH 21 done: loss 0.0104 - lr 0.0000017
2022-05-19 06:59:08,578 DEV : loss 0.23153585195541382 - f1-score (micro avg)  0.8431
2022-05-19 06:59:08,886 BAD EPOCHS (no improvement): 4
2022-05-19 06:59:08,886 ----------------------------------------------------------------------------------------------------
2022-05-19 07:02:46,095 epoch 22 - iter 576/5765 - loss 0.00605968 - samples/sec: 10.61 - lr: 0.000002
2022-05-19 07:06:33,892 epoch 22 - iter 1152/5765 - loss 0.00750881 - samples/sec: 10.12 - lr: 0.000002
2022-05-19 07:10:19,120 epoch 22 - iter 1728/5765 - loss 0.00832184 - samples/sec: 10.23 - lr: 0.000002
2022-05-19 07:14:02,313 epoch 22 - iter 2304/5765 - loss 0.00827838 - samples/sec: 10.33 - lr: 0.000002
2022-05-19 07:17:44,937 epoch 22 - iter 2880/5765 - loss 0.00838502 - samples/sec: 10.35 - lr: 0.000002
2022-05-19 07:21:25,897 epoch 22 - iter 3456/5765 - loss 0.00912806 - samples/sec: 10.43 - lr: 0.000002
2022-05-19 07:25:09,418 epoch 22 - iter 4032/5765 - loss 0.00932648 - samples/sec: 10.31 - lr: 0.000002
2022-05-19 07:28:45,075 epoch 22 - iter 4608/5765 - loss 0.00983719 - samples/sec: 10.69 - lr: 0.000002
2022-05-19 07:32:31,825 epoch 22 - iter 5184/5765 - loss 0.00957425 - samples/sec: 10.16 - lr: 0.000002
2022-05-19 07:36:16,327 epoch 22 - iter 5760/5765 - loss 0.00927034 - samples/sec: 10.27 - lr: 0.000001
2022-05-19 07:36:18,352 ----------------------------------------------------------------------------------------------------
2022-05-19 07:36:18,353 EPOCH 22 done: loss 0.0093 - lr 0.0000015
2022-05-19 07:39:12,227 DEV : loss 0.2305372655391693 - f1-score (micro avg)  0.843
2022-05-19 07:39:12,591 BAD EPOCHS (no improvement): 4
2022-05-19 07:39:12,592 ----------------------------------------------------------------------------------------------------
2022-05-19 07:42:53,156 epoch 23 - iter 576/5765 - loss 0.00882089 - samples/sec: 10.45 - lr: 0.000001
2022-05-19 07:46:35,802 epoch 23 - iter 1152/5765 - loss 0.00854086 - samples/sec: 10.35 - lr: 0.000001
2022-05-19 07:50:16,975 epoch 23 - iter 1728/5765 - loss 0.00853054 - samples/sec: 10.42 - lr: 0.000001
2022-05-19 07:53:58,825 epoch 23 - iter 2304/5765 - loss 0.00800249 - samples/sec: 10.39 - lr: 0.000001
2022-05-19 07:57:36,112 epoch 23 - iter 2880/5765 - loss 0.00802992 - samples/sec: 10.61 - lr: 0.000001
2022-05-19 08:01:15,489 epoch 23 - iter 3456/5765 - loss 0.00772901 - samples/sec: 10.51 - lr: 0.000001
2022-05-19 08:04:58,792 epoch 23 - iter 4032/5765 - loss 0.00786667 - samples/sec: 10.32 - lr: 0.000001
2022-05-19 08:08:45,455 epoch 23 - iter 4608/5765 - loss 0.00826914 - samples/sec: 10.17 - lr: 0.000001
2022-05-19 08:12:28,150 epoch 23 - iter 5184/5765 - loss 0.00860464 - samples/sec: 10.35 - lr: 0.000001
2022-05-19 08:16:11,532 epoch 23 - iter 5760/5765 - loss 0.00877429 - samples/sec: 10.32 - lr: 0.000001
2022-05-19 08:16:13,564 ----------------------------------------------------------------------------------------------------
2022-05-19 08:16:13,565 EPOCH 23 done: loss 0.0088 - lr 0.0000013
2022-05-19 08:19:08,120 DEV : loss 0.23388706147670746 - f1-score (micro avg)  0.8438
2022-05-19 08:19:08,466 BAD EPOCHS (no improvement): 4
2022-05-19 08:19:08,467 ----------------------------------------------------------------------------------------------------
2022-05-19 08:22:52,466 epoch 24 - iter 576/5765 - loss 0.00916224 - samples/sec: 10.29 - lr: 0.000001
2022-05-19 08:26:36,878 epoch 24 - iter 1152/5765 - loss 0.00812760 - samples/sec: 10.27 - lr: 0.000001
2022-05-19 08:30:24,699 epoch 24 - iter 1728/5765 - loss 0.00866794 - samples/sec: 10.12 - lr: 0.000001
2022-05-19 08:34:07,997 epoch 24 - iter 2304/5765 - loss 0.00857590 - samples/sec: 10.32 - lr: 0.000001
2022-05-19 08:37:48,274 epoch 24 - iter 2880/5765 - loss 0.00841715 - samples/sec: 10.46 - lr: 0.000001
2022-05-19 08:41:32,670 epoch 24 - iter 3456/5765 - loss 0.00800978 - samples/sec: 10.27 - lr: 0.000001
2022-05-19 08:45:09,497 epoch 24 - iter 4032/5765 - loss 0.00765714 - samples/sec: 10.63 - lr: 0.000001
2022-05-19 08:48:55,992 epoch 24 - iter 4608/5765 - loss 0.00757321 - samples/sec: 10.17 - lr: 0.000001
2022-05-19 08:52:37,974 epoch 24 - iter 5184/5765 - loss 0.00749509 - samples/sec: 10.38 - lr: 0.000001
2022-05-19 08:56:27,049 epoch 24 - iter 5760/5765 - loss 0.00773291 - samples/sec: 10.06 - lr: 0.000001
2022-05-19 08:56:29,130 ----------------------------------------------------------------------------------------------------
2022-05-19 08:56:29,131 EPOCH 24 done: loss 0.0077 - lr 0.0000011
2022-05-19 08:59:19,183 DEV : loss 0.23843280971050262 - f1-score (micro avg)  0.8447
2022-05-19 08:59:19,550 BAD EPOCHS (no improvement): 4
2022-05-19 08:59:19,551 ----------------------------------------------------------------------------------------------------
2022-05-19 09:03:04,171 epoch 25 - iter 576/5765 - loss 0.00681014 - samples/sec: 10.26 - lr: 0.000001
2022-05-19 09:06:42,870 epoch 25 - iter 1152/5765 - loss 0.00748030 - samples/sec: 10.54 - lr: 0.000001
2022-05-19 09:10:28,268 epoch 25 - iter 1728/5765 - loss 0.00668411 - samples/sec: 10.22 - lr: 0.000001
2022-05-19 09:14:11,826 epoch 25 - iter 2304/5765 - loss 0.00671061 - samples/sec: 10.31 - lr: 0.000001
2022-05-19 09:17:53,960 epoch 25 - iter 2880/5765 - loss 0.00662488 - samples/sec: 10.37 - lr: 0.000001
2022-05-19 09:21:42,596 epoch 25 - iter 3456/5765 - loss 0.00670917 - samples/sec: 10.08 - lr: 0.000001
2022-05-19 09:25:24,617 epoch 25 - iter 4032/5765 - loss 0.00641609 - samples/sec: 10.38 - lr: 0.000001
2022-05-19 09:29:13,873 epoch 25 - iter 4608/5765 - loss 0.00709427 - samples/sec: 10.05 - lr: 0.000001
2022-05-19 09:32:55,675 epoch 25 - iter 5184/5765 - loss 0.00697931 - samples/sec: 10.39 - lr: 0.000001
2022-05-19 09:36:38,418 epoch 25 - iter 5760/5765 - loss 0.00715217 - samples/sec: 10.35 - lr: 0.000001
2022-05-19 09:36:40,420 ----------------------------------------------------------------------------------------------------
2022-05-19 09:36:40,421 EPOCH 25 done: loss 0.0071 - lr 0.0000009
2022-05-19 09:39:30,973 DEV : loss 0.2343122810125351 - f1-score (micro avg)  0.8469
2022-05-19 09:39:31,307 BAD EPOCHS (no improvement): 4
2022-05-19 09:39:31,307 ----------------------------------------------------------------------------------------------------
2022-05-19 09:43:13,025 epoch 26 - iter 576/5765 - loss 0.00588438 - samples/sec: 10.39 - lr: 0.000001
2022-05-19 09:46:51,420 epoch 26 - iter 1152/5765 - loss 0.00521902 - samples/sec: 10.55 - lr: 0.000001
2022-05-19 09:50:36,905 epoch 26 - iter 1728/5765 - loss 0.00540906 - samples/sec: 10.22 - lr: 0.000001
2022-05-19 09:54:18,075 epoch 26 - iter 2304/5765 - loss 0.00548763 - samples/sec: 10.42 - lr: 0.000001
2022-05-19 09:57:58,632 epoch 26 - iter 2880/5765 - loss 0.00616011 - samples/sec: 10.45 - lr: 0.000001
2022-05-19 10:01:41,865 epoch 26 - iter 3456/5765 - loss 0.00613096 - samples/sec: 10.32 - lr: 0.000001
2022-05-19 10:05:25,287 epoch 26 - iter 4032/5765 - loss 0.00625907 - samples/sec: 10.31 - lr: 0.000001
2022-05-19 10:09:07,705 epoch 26 - iter 4608/5765 - loss 0.00651741 - samples/sec: 10.36 - lr: 0.000001
2022-05-19 10:12:48,972 epoch 26 - iter 5184/5765 - loss 0.00667917 - samples/sec: 10.42 - lr: 0.000001
2022-05-19 10:16:37,191 epoch 26 - iter 5760/5765 - loss 0.00667284 - samples/sec: 10.10 - lr: 0.000001
2022-05-19 10:16:38,970 ----------------------------------------------------------------------------------------------------
2022-05-19 10:16:38,972 EPOCH 26 done: loss 0.0067 - lr 0.0000007
2022-05-19 10:19:34,101 DEV : loss 0.23737730085849762 - f1-score (micro avg)  0.8442
2022-05-19 10:19:34,420 BAD EPOCHS (no improvement): 4
2022-05-19 10:19:34,420 ----------------------------------------------------------------------------------------------------
2022-05-19 10:23:14,509 epoch 27 - iter 576/5765 - loss 0.00600784 - samples/sec: 10.47 - lr: 0.000001
2022-05-19 10:26:58,774 epoch 27 - iter 1152/5765 - loss 0.00669300 - samples/sec: 10.28 - lr: 0.000001
2022-05-19 10:30:43,155 epoch 27 - iter 1728/5765 - loss 0.00656867 - samples/sec: 10.27 - lr: 0.000001
2022-05-19 10:34:27,271 epoch 27 - iter 2304/5765 - loss 0.00597898 - samples/sec: 10.28 - lr: 0.000001
2022-05-19 10:38:09,264 epoch 27 - iter 2880/5765 - loss 0.00576892 - samples/sec: 10.38 - lr: 0.000001
2022-05-19 10:41:45,646 epoch 27 - iter 3456/5765 - loss 0.00599306 - samples/sec: 10.65 - lr: 0.000001
2022-05-19 10:45:27,829 epoch 27 - iter 4032/5765 - loss 0.00608622 - samples/sec: 10.37 - lr: 0.000001
2022-05-19 10:49:10,405 epoch 27 - iter 4608/5765 - loss 0.00601241 - samples/sec: 10.35 - lr: 0.000001
2022-05-19 10:52:57,610 epoch 27 - iter 5184/5765 - loss 0.00609648 - samples/sec: 10.14 - lr: 0.000001
2022-05-19 10:56:49,003 epoch 27 - iter 5760/5765 - loss 0.00610588 - samples/sec: 9.96 - lr: 0.000001
2022-05-19 10:56:50,940 ----------------------------------------------------------------------------------------------------
2022-05-19 10:56:50,941 EPOCH 27 done: loss 0.0061 - lr 0.0000006
2022-05-19 10:59:39,378 DEV : loss 0.23975524306297302 - f1-score (micro avg)  0.8439
2022-05-19 10:59:39,695 BAD EPOCHS (no improvement): 4
2022-05-19 10:59:39,696 ----------------------------------------------------------------------------------------------------
2022-05-19 11:03:22,456 epoch 28 - iter 576/5765 - loss 0.00411855 - samples/sec: 10.35 - lr: 0.000001
2022-05-19 11:07:01,806 epoch 28 - iter 1152/5765 - loss 0.00528405 - samples/sec: 10.51 - lr: 0.000001
2022-05-19 11:10:42,784 epoch 28 - iter 1728/5765 - loss 0.00488284 - samples/sec: 10.43 - lr: 0.000001
2022-05-19 11:14:31,869 epoch 28 - iter 2304/5765 - loss 0.00650189 - samples/sec: 10.06 - lr: 0.000000
2022-05-19 11:18:16,674 epoch 28 - iter 2880/5765 - loss 0.00604081 - samples/sec: 10.25 - lr: 0.000000
2022-05-19 11:22:03,281 epoch 28 - iter 3456/5765 - loss 0.00622200 - samples/sec: 10.17 - lr: 0.000000
2022-05-19 11:25:43,638 epoch 28 - iter 4032/5765 - loss 0.00597653 - samples/sec: 10.46 - lr: 0.000000
2022-05-19 11:29:20,567 epoch 28 - iter 4608/5765 - loss 0.00564676 - samples/sec: 10.62 - lr: 0.000000
2022-05-19 11:33:02,828 epoch 28 - iter 5184/5765 - loss 0.00553745 - samples/sec: 10.37 - lr: 0.000000
2022-05-19 11:36:43,493 epoch 28 - iter 5760/5765 - loss 0.00562592 - samples/sec: 10.44 - lr: 0.000000
2022-05-19 11:36:45,394 ----------------------------------------------------------------------------------------------------
2022-05-19 11:36:45,395 EPOCH 28 done: loss 0.0056 - lr 0.0000004
2022-05-19 11:39:38,832 DEV : loss 0.2424999475479126 - f1-score (micro avg)  0.8437
2022-05-19 11:39:39,193 BAD EPOCHS (no improvement): 4
2022-05-19 11:39:39,193 ----------------------------------------------------------------------------------------------------
2022-05-19 11:43:21,838 epoch 29 - iter 576/5765 - loss 0.00632972 - samples/sec: 10.35 - lr: 0.000000
2022-05-19 11:47:03,673 epoch 29 - iter 1152/5765 - loss 0.00721265 - samples/sec: 10.39 - lr: 0.000000
2022-05-19 11:50:46,382 epoch 29 - iter 1728/5765 - loss 0.00733181 - samples/sec: 10.35 - lr: 0.000000
2022-05-19 11:54:26,497 epoch 29 - iter 2304/5765 - loss 0.00668460 - samples/sec: 10.47 - lr: 0.000000
2022-05-19 11:58:06,488 epoch 29 - iter 2880/5765 - loss 0.00647784 - samples/sec: 10.48 - lr: 0.000000
2022-05-19 12:01:52,480 epoch 29 - iter 3456/5765 - loss 0.00624926 - samples/sec: 10.20 - lr: 0.000000
2022-05-19 12:05:35,070 epoch 29 - iter 4032/5765 - loss 0.00588373 - samples/sec: 10.35 - lr: 0.000000
2022-05-19 12:09:19,751 epoch 29 - iter 4608/5765 - loss 0.00574275 - samples/sec: 10.26 - lr: 0.000000
2022-05-19 12:13:00,569 epoch 29 - iter 5184/5765 - loss 0.00562722 - samples/sec: 10.44 - lr: 0.000000
2022-05-19 12:16:42,415 epoch 29 - iter 5760/5765 - loss 0.00547285 - samples/sec: 10.39 - lr: 0.000000
2022-05-19 12:16:44,644 ----------------------------------------------------------------------------------------------------
2022-05-19 12:16:44,645 EPOCH 29 done: loss 0.0055 - lr 0.0000002
2022-05-19 12:19:40,582 DEV : loss 0.2415909469127655 - f1-score (micro avg)  0.8457
2022-05-19 12:19:40,905 BAD EPOCHS (no improvement): 4
2022-05-19 12:19:40,905 ----------------------------------------------------------------------------------------------------
2022-05-19 12:23:16,292 epoch 30 - iter 576/5765 - loss 0.00555991 - samples/sec: 10.70 - lr: 0.000000
2022-05-19 12:26:58,400 epoch 30 - iter 1152/5765 - loss 0.00616193 - samples/sec: 10.38 - lr: 0.000000
2022-05-19 12:30:39,501 epoch 30 - iter 1728/5765 - loss 0.00535459 - samples/sec: 10.42 - lr: 0.000000
2022-05-19 12:34:20,841 epoch 30 - iter 2304/5765 - loss 0.00535284 - samples/sec: 10.41 - lr: 0.000000
2022-05-19 12:38:04,154 epoch 30 - iter 2880/5765 - loss 0.00522350 - samples/sec: 10.32 - lr: 0.000000
2022-05-19 12:41:50,315 epoch 30 - iter 3456/5765 - loss 0.00540519 - samples/sec: 10.19 - lr: 0.000000
2022-05-19 12:45:33,113 epoch 30 - iter 4032/5765 - loss 0.00501671 - samples/sec: 10.34 - lr: 0.000000
2022-05-19 12:49:16,033 epoch 30 - iter 4608/5765 - loss 0.00495199 - samples/sec: 10.34 - lr: 0.000000
2022-05-19 12:52:56,870 epoch 30 - iter 5184/5765 - loss 0.00515928 - samples/sec: 10.44 - lr: 0.000000
2022-05-19 12:56:38,249 epoch 30 - iter 5760/5765 - loss 0.00521025 - samples/sec: 10.41 - lr: 0.000000
2022-05-19 12:56:40,058 ----------------------------------------------------------------------------------------------------
2022-05-19 12:56:40,059 EPOCH 30 done: loss 0.0052 - lr 0.0000000
2022-05-19 12:59:36,634 DEV : loss 0.24216654896736145 - f1-score (micro avg)  0.8462
2022-05-19 12:59:36,955 BAD EPOCHS (no improvement): 4
2022-05-19 12:59:38,501 ----------------------------------------------------------------------------------------------------
2022-05-19 12:59:38,502 Testing using last state of model ...
2022-05-19 13:02:22,907 0.9009	0.8872	0.894	0.8151
2022-05-19 13:02:22,908 
Results:
- F-score (micro) 0.894
- F-score (macro) 0.891
- Accuracy 0.8151

By class:
              precision    recall  f1-score   support

         LOC     0.9039    0.9104    0.9071      4083
         ORG     0.8873    0.8557    0.8712      3166
         PER     0.9207    0.9238    0.9222      2741
         DAT     0.8615    0.7896    0.8240      1150
         MON     0.9581    0.9608    0.9594       357
         TIM     0.7862    0.7530    0.7692       166
         PCT     0.9935    0.9744    0.9838       156

   micro avg     0.9009    0.8872    0.8940     11819
   macro avg     0.9016    0.8811    0.8910     11819
weighted avg     0.9004    0.8872    0.8936     11819
 samples avg     0.8151    0.8151    0.8151     11819

2022-05-19 13:02:22,908 ----------------------------------------------------------------------------------------------------
