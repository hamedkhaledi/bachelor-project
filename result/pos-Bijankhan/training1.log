2022-08-11 23:39:15,427 ----------------------------------------------------------------------------------------------------
2022-08-11 23:39:15,428 Model: "SequenceTagger(
  (embeddings): TransformerWordEmbeddings(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(100000, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (rnn): LSTM(768, 512, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=1024, out_features=41, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2022-08-11 23:39:15,429 ----------------------------------------------------------------------------------------------------
2022-08-11 23:39:15,429 Corpus: "Corpus: 67796 train + 8475 dev + 8474 test sentences"
2022-08-11 23:39:15,429 ----------------------------------------------------------------------------------------------------
2022-08-11 23:39:15,429 Parameters:
2022-08-11 23:39:15,429  - learning_rate: "5e-06"
2022-08-11 23:39:15,429  - mini_batch_size: "4"
2022-08-11 23:39:15,429  - patience: "3"
2022-08-11 23:39:15,429  - anneal_factor: "0.5"
2022-08-11 23:39:15,429  - max_epochs: "35"
2022-08-11 23:39:15,429  - shuffle: "True"
2022-08-11 23:39:15,429  - train_with_dev: "False"
2022-08-11 23:39:15,429  - batch_growth_annealing: "False"
2022-08-11 23:39:15,429 ----------------------------------------------------------------------------------------------------
2022-08-11 23:39:15,429 Model training base path: "data/pos-Bijankhan/model"
2022-08-11 23:39:15,429 ----------------------------------------------------------------------------------------------------
2022-08-11 23:39:15,429 Device: cuda:0
2022-08-11 23:39:15,429 ----------------------------------------------------------------------------------------------------
2022-08-11 23:39:15,429 Embeddings storage mode: cpu
2022-08-11 23:39:15,430 ----------------------------------------------------------------------------------------------------
2022-08-11 23:42:41,066 epoch 1 - iter 1694/16949 - loss 3.68121152 - samples/sec: 32.97 - lr: 0.000000
2022-08-11 23:46:07,927 epoch 1 - iter 3388/16949 - loss 3.48392638 - samples/sec: 32.77 - lr: 0.000000
2022-08-11 23:49:26,185 epoch 1 - iter 5082/16949 - loss 3.20977505 - samples/sec: 34.20 - lr: 0.000000
2022-08-11 23:52:52,518 epoch 1 - iter 6776/16949 - loss 2.93669448 - samples/sec: 32.86 - lr: 0.000001
2022-08-11 23:56:18,447 epoch 1 - iter 8470/16949 - loss 2.68078624 - samples/sec: 32.92 - lr: 0.000001
2022-08-11 23:59:45,246 epoch 1 - iter 10164/16949 - loss 2.43999663 - samples/sec: 32.78 - lr: 0.000001
2022-08-12 00:03:25,072 epoch 1 - iter 11858/16949 - loss 2.20755540 - samples/sec: 30.84 - lr: 0.000001
2022-08-12 00:06:53,029 epoch 1 - iter 13552/16949 - loss 2.01611296 - samples/sec: 32.60 - lr: 0.000001
2022-08-12 00:10:26,086 epoch 1 - iter 15246/16949 - loss 1.84565036 - samples/sec: 31.82 - lr: 0.000001
2022-08-12 00:13:48,046 epoch 1 - iter 16940/16949 - loss 1.73016472 - samples/sec: 33.57 - lr: 0.000001
2022-08-12 00:13:49,077 ----------------------------------------------------------------------------------------------------
2022-08-12 00:13:49,078 EPOCH 1 done: loss 1.7297 - lr 0.0000014
2022-08-12 00:56:18,319 DEV : loss 0.2736215889453888 - f1-score (micro avg)  0.9386
2022-08-12 00:56:18,808 BAD EPOCHS (no improvement): 4
2022-08-12 00:56:18,809 ----------------------------------------------------------------------------------------------------
2022-08-12 00:59:47,435 epoch 2 - iter 1694/16949 - loss 0.39808314 - samples/sec: 32.50 - lr: 0.000002
2022-08-12 01:03:16,371 epoch 2 - iter 3388/16949 - loss 0.37032376 - samples/sec: 32.45 - lr: 0.000002
2022-08-12 01:06:53,668 epoch 2 - iter 5082/16949 - loss 0.35112636 - samples/sec: 31.20 - lr: 0.000002
2022-08-12 01:10:24,807 epoch 2 - iter 6776/16949 - loss 0.33447107 - samples/sec: 32.11 - lr: 0.000002
2022-08-12 01:13:55,822 epoch 2 - iter 8470/16949 - loss 0.32072468 - samples/sec: 32.13 - lr: 0.000002
2022-08-12 01:17:26,298 epoch 2 - iter 10164/16949 - loss 0.30914760 - samples/sec: 32.21 - lr: 0.000002
2022-08-12 01:20:59,416 epoch 2 - iter 11858/16949 - loss 0.29761400 - samples/sec: 31.81 - lr: 0.000002
2022-08-12 01:24:30,653 epoch 2 - iter 13552/16949 - loss 0.28821445 - samples/sec: 32.10 - lr: 0.000003
2022-08-12 01:28:05,931 epoch 2 - iter 15246/16949 - loss 0.27940071 - samples/sec: 31.50 - lr: 0.000003
2022-08-12 01:31:42,760 epoch 2 - iter 16940/16949 - loss 0.27190829 - samples/sec: 31.27 - lr: 0.000003
2022-08-12 01:31:44,015 ----------------------------------------------------------------------------------------------------
2022-08-12 01:31:44,015 EPOCH 2 done: loss 0.2719 - lr 0.0000029
2022-08-12 02:13:01,176 DEV : loss 0.13418756425380707 - f1-score (micro avg)  0.9663
2022-08-12 02:13:01,724 BAD EPOCHS (no improvement): 4
2022-08-12 02:13:01,725 ----------------------------------------------------------------------------------------------------
2022-08-12 02:16:58,983 epoch 3 - iter 1694/16949 - loss 0.18980411 - samples/sec: 28.58 - lr: 0.000003
2022-08-12 02:20:46,677 epoch 3 - iter 3388/16949 - loss 0.18663849 - samples/sec: 29.78 - lr: 0.000003
2022-08-12 02:24:32,589 epoch 3 - iter 5082/16949 - loss 0.18329619 - samples/sec: 30.01 - lr: 0.000003
2022-08-12 02:28:18,487 epoch 3 - iter 6776/16949 - loss 0.18010575 - samples/sec: 30.01 - lr: 0.000003
2022-08-12 02:32:04,459 epoch 3 - iter 8470/16949 - loss 0.17752239 - samples/sec: 30.01 - lr: 0.000004
2022-08-12 02:35:53,182 epoch 3 - iter 10164/16949 - loss 0.17441718 - samples/sec: 29.64 - lr: 0.000004
2022-08-12 02:39:38,454 epoch 3 - iter 11858/16949 - loss 0.17112739 - samples/sec: 30.10 - lr: 0.000004
2022-08-12 02:43:24,064 epoch 3 - iter 13552/16949 - loss 0.16828392 - samples/sec: 30.05 - lr: 0.000004
2022-08-12 02:47:21,507 epoch 3 - iter 15246/16949 - loss 0.16561984 - samples/sec: 28.55 - lr: 0.000004
2022-08-12 02:51:10,591 epoch 3 - iter 16940/16949 - loss 0.16244733 - samples/sec: 29.60 - lr: 0.000004
2022-08-12 02:51:11,853 ----------------------------------------------------------------------------------------------------
2022-08-12 02:51:11,853 EPOCH 3 done: loss 0.1624 - lr 0.0000043
2022-08-12 03:34:38,295 DEV : loss 0.12612050771713257 - f1-score (micro avg)  0.9693
2022-08-12 03:34:38,812 BAD EPOCHS (no improvement): 4
2022-08-12 03:34:38,813 ----------------------------------------------------------------------------------------------------
2022-08-12 03:38:25,598 epoch 4 - iter 1694/16949 - loss 0.12837015 - samples/sec: 29.90 - lr: 0.000004
2022-08-12 03:42:09,878 epoch 4 - iter 3388/16949 - loss 0.12900480 - samples/sec: 30.23 - lr: 0.000005
2022-08-12 03:46:00,218 epoch 4 - iter 5082/16949 - loss 0.12633718 - samples/sec: 29.43 - lr: 0.000005
2022-08-12 03:49:48,659 epoch 4 - iter 6776/16949 - loss 0.12348951 - samples/sec: 29.68 - lr: 0.000005
2022-08-12 03:53:32,425 epoch 4 - iter 8470/16949 - loss 0.12202944 - samples/sec: 30.30 - lr: 0.000005
2022-08-12 03:57:23,156 epoch 4 - iter 10164/16949 - loss 0.12011371 - samples/sec: 29.39 - lr: 0.000005
2022-08-12 04:01:03,568 epoch 4 - iter 11858/16949 - loss 0.11800977 - samples/sec: 30.76 - lr: 0.000005
2022-08-12 04:04:50,486 epoch 4 - iter 13552/16949 - loss 0.11645399 - samples/sec: 29.88 - lr: 0.000005
2022-08-12 04:08:32,612 epoch 4 - iter 15246/16949 - loss 0.11476307 - samples/sec: 30.52 - lr: 0.000005
2022-08-12 04:12:16,816 epoch 4 - iter 16940/16949 - loss 0.11333493 - samples/sec: 30.24 - lr: 0.000005
2022-08-12 04:12:17,931 ----------------------------------------------------------------------------------------------------
2022-08-12 04:12:17,931 EPOCH 4 done: loss 0.1133 - lr 0.0000049
2022-08-12 04:55:58,832 DEV : loss 0.1232493594288826 - f1-score (micro avg)  0.971
2022-08-12 04:55:59,338 BAD EPOCHS (no improvement): 4
2022-08-12 04:55:59,339 ----------------------------------------------------------------------------------------------------
2022-08-12 04:59:50,164 epoch 5 - iter 1694/16949 - loss 0.09267069 - samples/sec: 29.37 - lr: 0.000005
2022-08-12 05:03:37,353 epoch 5 - iter 3388/16949 - loss 0.09062500 - samples/sec: 29.84 - lr: 0.000005
2022-08-12 05:07:21,794 epoch 5 - iter 5082/16949 - loss 0.08985078 - samples/sec: 30.21 - lr: 0.000005
2022-08-12 05:11:14,475 epoch 5 - iter 6776/16949 - loss 0.08966068 - samples/sec: 29.14 - lr: 0.000005
2022-08-12 05:14:57,522 epoch 5 - iter 8470/16949 - loss 0.08956099 - samples/sec: 30.40 - lr: 0.000005
2022-08-12 05:18:46,502 epoch 5 - iter 10164/16949 - loss 0.08904911 - samples/sec: 29.61 - lr: 0.000005
2022-08-12 05:22:34,192 epoch 5 - iter 11858/16949 - loss 0.08801406 - samples/sec: 29.78 - lr: 0.000005
2022-08-12 05:26:18,572 epoch 5 - iter 13552/16949 - loss 0.08740056 - samples/sec: 30.22 - lr: 0.000005
2022-08-12 05:30:09,416 epoch 5 - iter 15246/16949 - loss 0.08691470 - samples/sec: 29.37 - lr: 0.000005
2022-08-12 05:33:54,406 epoch 5 - iter 16940/16949 - loss 0.08624003 - samples/sec: 30.14 - lr: 0.000005
2022-08-12 05:33:55,681 ----------------------------------------------------------------------------------------------------
2022-08-12 05:33:55,682 EPOCH 5 done: loss 0.0863 - lr 0.0000048
2022-08-12 06:21:02,655 DEV : loss 0.13064227998256683 - f1-score (micro avg)  0.9709
2022-08-12 06:21:03,171 BAD EPOCHS (no improvement): 4
2022-08-12 06:21:03,171 ----------------------------------------------------------------------------------------------------
2022-08-12 06:25:03,287 epoch 6 - iter 1694/16949 - loss 0.07520495 - samples/sec: 28.24 - lr: 0.000005
2022-08-12 06:28:58,915 epoch 6 - iter 3388/16949 - loss 0.07385591 - samples/sec: 28.77 - lr: 0.000005
2022-08-12 06:32:49,578 epoch 6 - iter 5082/16949 - loss 0.07343202 - samples/sec: 29.39 - lr: 0.000005
2022-08-12 06:36:36,965 epoch 6 - iter 6776/16949 - loss 0.07299456 - samples/sec: 29.82 - lr: 0.000005
2022-08-12 06:40:22,582 epoch 6 - iter 8470/16949 - loss 0.07263259 - samples/sec: 30.05 - lr: 0.000005
2022-08-12 06:44:08,543 epoch 6 - iter 10164/16949 - loss 0.07260628 - samples/sec: 30.01 - lr: 0.000005
2022-08-12 06:47:52,770 epoch 6 - iter 11858/16949 - loss 0.07241164 - samples/sec: 30.24 - lr: 0.000005
2022-08-12 06:51:41,843 epoch 6 - iter 13552/16949 - loss 0.07196738 - samples/sec: 29.60 - lr: 0.000005
2022-08-12 06:55:38,656 epoch 6 - iter 15246/16949 - loss 0.07167603 - samples/sec: 28.63 - lr: 0.000005
2022-08-12 06:59:40,337 epoch 6 - iter 16940/16949 - loss 0.07157643 - samples/sec: 28.05 - lr: 0.000005
2022-08-12 06:59:41,433 ----------------------------------------------------------------------------------------------------
2022-08-12 06:59:41,433 EPOCH 6 done: loss 0.0716 - lr 0.0000046
2022-08-12 07:45:24,188 DEV : loss 0.13906709849834442 - f1-score (micro avg)  0.9701
2022-08-12 07:45:24,734 BAD EPOCHS (no improvement): 4
2022-08-12 07:45:24,735 ----------------------------------------------------------------------------------------------------
2022-08-12 07:49:07,285 epoch 7 - iter 1694/16949 - loss 0.06053135 - samples/sec: 30.47 - lr: 0.000005
2022-08-12 07:52:48,969 epoch 7 - iter 3388/16949 - loss 0.06124705 - samples/sec: 30.58 - lr: 0.000005
2022-08-12 07:56:30,631 epoch 7 - iter 5082/16949 - loss 0.06088903 - samples/sec: 30.59 - lr: 0.000005
2022-08-12 08:00:12,491 epoch 7 - iter 6776/16949 - loss 0.06043277 - samples/sec: 30.56 - lr: 0.000005
2022-08-12 08:04:02,120 epoch 7 - iter 8470/16949 - loss 0.06051289 - samples/sec: 29.53 - lr: 0.000005
2022-08-12 08:07:45,094 epoch 7 - iter 10164/16949 - loss 0.06128793 - samples/sec: 30.41 - lr: 0.000005
2022-08-12 08:11:37,797 epoch 7 - iter 11858/16949 - loss 0.06149833 - samples/sec: 29.14 - lr: 0.000004
2022-08-12 08:15:22,177 epoch 7 - iter 13552/16949 - loss 0.06129173 - samples/sec: 30.22 - lr: 0.000004
2022-08-12 08:19:10,751 epoch 7 - iter 15246/16949 - loss 0.06135647 - samples/sec: 29.66 - lr: 0.000004
2022-08-12 08:22:54,918 epoch 7 - iter 16940/16949 - loss 0.06123360 - samples/sec: 30.25 - lr: 0.000004
2022-08-12 08:22:56,073 ----------------------------------------------------------------------------------------------------
2022-08-12 08:22:56,073 EPOCH 7 done: loss 0.0612 - lr 0.0000044
2022-08-12 09:08:10,686 DEV : loss 0.15278883278369904 - f1-score (micro avg)  0.9697
2022-08-12 09:08:11,217 BAD EPOCHS (no improvement): 4
2022-08-12 09:08:11,217 ----------------------------------------------------------------------------------------------------
2022-08-12 09:11:57,752 epoch 8 - iter 1694/16949 - loss 0.05169602 - samples/sec: 29.93 - lr: 0.000004
2022-08-12 09:15:41,851 epoch 8 - iter 3388/16949 - loss 0.05223328 - samples/sec: 30.25 - lr: 0.000004
2022-08-12 09:19:28,397 epoch 8 - iter 5082/16949 - loss 0.05218028 - samples/sec: 29.93 - lr: 0.000004
2022-08-12 09:23:21,741 epoch 8 - iter 6776/16949 - loss 0.05215475 - samples/sec: 29.06 - lr: 0.000004
2022-08-12 09:27:01,105 epoch 8 - iter 8470/16949 - loss 0.05213192 - samples/sec: 30.91 - lr: 0.000004
2022-08-12 09:30:43,855 epoch 8 - iter 10164/16949 - loss 0.05251830 - samples/sec: 30.44 - lr: 0.000004
2022-08-12 09:34:25,930 epoch 8 - iter 11858/16949 - loss 0.05253939 - samples/sec: 30.53 - lr: 0.000004
2022-08-12 09:38:09,786 epoch 8 - iter 13552/16949 - loss 0.05254020 - samples/sec: 30.29 - lr: 0.000004
2022-08-12 09:41:52,415 epoch 8 - iter 15246/16949 - loss 0.05266112 - samples/sec: 30.45 - lr: 0.000004
2022-08-12 09:45:36,958 epoch 8 - iter 16940/16949 - loss 0.05278060 - samples/sec: 30.20 - lr: 0.000004
2022-08-12 09:45:38,089 ----------------------------------------------------------------------------------------------------
2022-08-12 09:45:38,089 EPOCH 8 done: loss 0.0528 - lr 0.0000043
2022-08-12 10:30:49,738 DEV : loss 0.16752271354198456 - f1-score (micro avg)  0.9693
2022-08-12 10:30:50,294 BAD EPOCHS (no improvement): 4
2022-08-12 10:30:50,295 ----------------------------------------------------------------------------------------------------
2022-08-12 10:34:42,075 epoch 9 - iter 1694/16949 - loss 0.04400159 - samples/sec: 29.25 - lr: 0.000004
2022-08-12 10:38:21,759 epoch 9 - iter 3388/16949 - loss 0.04450039 - samples/sec: 30.86 - lr: 0.000004
2022-08-12 10:42:04,681 epoch 9 - iter 5082/16949 - loss 0.04547465 - samples/sec: 30.41 - lr: 0.000004
2022-08-12 10:45:48,124 epoch 9 - iter 6776/16949 - loss 0.04508184 - samples/sec: 30.34 - lr: 0.000004
2022-08-12 10:49:32,758 epoch 9 - iter 8470/16949 - loss 0.04513461 - samples/sec: 30.18 - lr: 0.000004
2022-08-12 10:53:15,430 epoch 9 - iter 10164/16949 - loss 0.04547460 - samples/sec: 30.45 - lr: 0.000004
2022-08-12 10:57:00,675 epoch 9 - iter 11858/16949 - loss 0.04547736 - samples/sec: 30.10 - lr: 0.000004
2022-08-12 11:00:49,821 epoch 9 - iter 13552/16949 - loss 0.04568130 - samples/sec: 29.59 - lr: 0.000004
2022-08-12 11:04:38,405 epoch 9 - iter 15246/16949 - loss 0.04559533 - samples/sec: 29.66 - lr: 0.000004
2022-08-12 11:08:35,750 epoch 9 - iter 16940/16949 - loss 0.04559199 - samples/sec: 28.57 - lr: 0.000004
2022-08-12 11:08:36,861 ----------------------------------------------------------------------------------------------------
2022-08-12 11:08:36,862 EPOCH 9 done: loss 0.0456 - lr 0.0000041
2022-08-12 11:55:02,266 DEV : loss 0.19601194560527802 - f1-score (micro avg)  0.9682
2022-08-12 11:55:02,779 BAD EPOCHS (no improvement): 4
2022-08-12 11:55:02,779 ----------------------------------------------------------------------------------------------------
2022-08-12 11:58:42,917 epoch 10 - iter 1694/16949 - loss 0.03889345 - samples/sec: 30.80 - lr: 0.000004
2022-08-12 12:02:31,200 epoch 10 - iter 3388/16949 - loss 0.03913349 - samples/sec: 29.70 - lr: 0.000004
2022-08-12 12:06:16,129 epoch 10 - iter 5082/16949 - loss 0.03887086 - samples/sec: 30.14 - lr: 0.000004
2022-08-12 12:09:59,904 epoch 10 - iter 6776/16949 - loss 0.03921568 - samples/sec: 30.30 - lr: 0.000004
2022-08-12 12:13:44,348 epoch 10 - iter 8470/16949 - loss 0.03922629 - samples/sec: 30.21 - lr: 0.000004
2022-08-12 12:17:26,303 epoch 10 - iter 10164/16949 - loss 0.03935885 - samples/sec: 30.55 - lr: 0.000004
2022-08-12 12:21:25,648 epoch 10 - iter 11858/16949 - loss 0.03963778 - samples/sec: 28.33 - lr: 0.000004
2022-08-12 12:25:09,711 epoch 10 - iter 13552/16949 - loss 0.03967110 - samples/sec: 30.26 - lr: 0.000004
2022-08-12 12:28:56,046 epoch 10 - iter 15246/16949 - loss 0.03968734 - samples/sec: 29.96 - lr: 0.000004
2022-08-12 12:32:41,026 epoch 10 - iter 16940/16949 - loss 0.03977778 - samples/sec: 30.14 - lr: 0.000004
2022-08-12 12:32:42,208 ----------------------------------------------------------------------------------------------------
2022-08-12 12:32:42,208 EPOCH 10 done: loss 0.0398 - lr 0.0000040
2022-08-12 13:19:11,595 DEV : loss 0.21083234250545502 - f1-score (micro avg)  0.9683
2022-08-12 13:19:12,101 BAD EPOCHS (no improvement): 4
2022-08-12 13:19:12,101 ----------------------------------------------------------------------------------------------------
2022-08-12 13:22:56,510 epoch 11 - iter 1694/16949 - loss 0.03340899 - samples/sec: 30.21 - lr: 0.000004
2022-08-12 13:26:43,067 epoch 11 - iter 3388/16949 - loss 0.03388754 - samples/sec: 29.93 - lr: 0.000004
2022-08-12 13:30:26,967 epoch 11 - iter 5082/16949 - loss 0.03364851 - samples/sec: 30.28 - lr: 0.000004
2022-08-12 13:34:25,787 epoch 11 - iter 6776/16949 - loss 0.03355032 - samples/sec: 28.39 - lr: 0.000004
2022-08-12 13:38:09,916 epoch 11 - iter 8470/16949 - loss 0.03392544 - samples/sec: 30.25 - lr: 0.000004
2022-08-12 13:41:55,285 epoch 11 - iter 10164/16949 - loss 0.03423542 - samples/sec: 30.08 - lr: 0.000004
2022-08-12 13:45:36,877 epoch 11 - iter 11858/16949 - loss 0.03457461 - samples/sec: 30.60 - lr: 0.000004
2022-08-12 13:49:22,275 epoch 11 - iter 13552/16949 - loss 0.03477531 - samples/sec: 30.08 - lr: 0.000004
2022-08-12 13:53:06,832 epoch 11 - iter 15246/16949 - loss 0.03510826 - samples/sec: 30.19 - lr: 0.000004
2022-08-12 13:56:56,757 epoch 11 - iter 16940/16949 - loss 0.03515830 - samples/sec: 29.49 - lr: 0.000004
2022-08-12 13:56:58,029 ----------------------------------------------------------------------------------------------------
2022-08-12 13:56:58,029 EPOCH 11 done: loss 0.0352 - lr 0.0000038
2022-08-12 14:45:17,489 DEV : loss 0.22306957840919495 - f1-score (micro avg)  0.969
2022-08-12 14:45:18,060 BAD EPOCHS (no improvement): 4
2022-08-12 14:45:18,061 ----------------------------------------------------------------------------------------------------
2022-08-12 14:49:09,137 epoch 12 - iter 1694/16949 - loss 0.02858453 - samples/sec: 29.34 - lr: 0.000004
2022-08-12 14:52:55,400 epoch 12 - iter 3388/16949 - loss 0.02942179 - samples/sec: 29.97 - lr: 0.000004
2022-08-12 14:56:40,474 epoch 12 - iter 5082/16949 - loss 0.02965365 - samples/sec: 30.12 - lr: 0.000004
2022-08-12 15:00:25,651 epoch 12 - iter 6776/16949 - loss 0.03001954 - samples/sec: 30.11 - lr: 0.000004
2022-08-12 15:04:08,987 epoch 12 - iter 8470/16949 - loss 0.03031704 - samples/sec: 30.36 - lr: 0.000004
2022-08-12 15:07:50,133 epoch 12 - iter 10164/16949 - loss 0.03025841 - samples/sec: 30.66 - lr: 0.000004
2022-08-12 15:11:35,736 epoch 12 - iter 11858/16949 - loss 0.03025596 - samples/sec: 30.05 - lr: 0.000004
2022-08-12 15:15:17,779 epoch 12 - iter 13552/16949 - loss 0.03024990 - samples/sec: 30.54 - lr: 0.000004
2022-08-12 15:19:02,171 epoch 12 - iter 15246/16949 - loss 0.03069149 - samples/sec: 30.22 - lr: 0.000004
2022-08-12 15:22:56,432 epoch 12 - iter 16940/16949 - loss 0.03088904 - samples/sec: 28.94 - lr: 0.000004
2022-08-12 15:22:57,619 ----------------------------------------------------------------------------------------------------
2022-08-12 15:22:57,619 EPOCH 12 done: loss 0.0309 - lr 0.0000037
2022-08-12 16:08:48,244 DEV : loss 0.2510016858577728 - f1-score (micro avg)  0.9684
2022-08-12 16:08:48,731 BAD EPOCHS (no improvement): 4
2022-08-12 16:08:48,731 ----------------------------------------------------------------------------------------------------
2022-08-12 16:12:32,357 epoch 13 - iter 1694/16949 - loss 0.02441801 - samples/sec: 30.32 - lr: 0.000004
2022-08-12 16:16:13,392 epoch 13 - iter 3388/16949 - loss 0.02557731 - samples/sec: 30.67 - lr: 0.000004
2022-08-12 16:19:58,175 epoch 13 - iter 5082/16949 - loss 0.02640674 - samples/sec: 30.16 - lr: 0.000004
2022-08-12 16:23:40,229 epoch 13 - iter 6776/16949 - loss 0.02651641 - samples/sec: 30.53 - lr: 0.000004
2022-08-12 16:27:23,145 epoch 13 - iter 8470/16949 - loss 0.02681036 - samples/sec: 30.42 - lr: 0.000004
2022-08-12 16:31:04,816 epoch 13 - iter 10164/16949 - loss 0.02722675 - samples/sec: 30.59 - lr: 0.000004
2022-08-12 16:34:55,921 epoch 13 - iter 11858/16949 - loss 0.02756216 - samples/sec: 29.34 - lr: 0.000004
2022-08-12 16:38:39,248 epoch 13 - iter 13552/16949 - loss 0.02760732 - samples/sec: 30.36 - lr: 0.000004
2022-08-12 16:42:22,669 epoch 13 - iter 15246/16949 - loss 0.02784953 - samples/sec: 30.35 - lr: 0.000004
2022-08-12 16:46:05,205 epoch 13 - iter 16940/16949 - loss 0.02782301 - samples/sec: 30.47 - lr: 0.000003
2022-08-12 16:46:06,368 ----------------------------------------------------------------------------------------------------
2022-08-12 16:46:06,368 EPOCH 13 done: loss 0.0278 - lr 0.0000035
2022-08-12 17:32:27,354 DEV : loss 0.2828621566295624 - f1-score (micro avg)  0.9678
2022-08-12 17:32:27,875 BAD EPOCHS (no improvement): 4
2022-08-12 17:32:27,875 ----------------------------------------------------------------------------------------------------
2022-08-12 17:36:14,247 epoch 14 - iter 1694/16949 - loss 0.02377258 - samples/sec: 29.95 - lr: 0.000003
2022-08-12 17:39:57,285 epoch 14 - iter 3388/16949 - loss 0.02286071 - samples/sec: 30.40 - lr: 0.000003
2022-08-12 17:43:37,336 epoch 14 - iter 5082/16949 - loss 0.02260134 - samples/sec: 30.81 - lr: 0.000003
2022-08-12 17:47:31,208 epoch 14 - iter 6776/16949 - loss 0.02285671 - samples/sec: 28.99 - lr: 0.000003
2022-08-12 17:51:18,128 epoch 14 - iter 8470/16949 - loss 0.02360441 - samples/sec: 29.88 - lr: 0.000003
2022-08-12 17:55:05,443 epoch 14 - iter 10164/16949 - loss 0.02371415 - samples/sec: 29.83 - lr: 0.000003
2022-08-12 17:58:47,970 epoch 14 - iter 11858/16949 - loss 0.02399655 - samples/sec: 30.47 - lr: 0.000003
2022-08-12 18:02:30,159 epoch 14 - iter 13552/16949 - loss 0.02424089 - samples/sec: 30.51 - lr: 0.000003
2022-08-12 18:06:12,878 epoch 14 - iter 15246/16949 - loss 0.02441080 - samples/sec: 30.44 - lr: 0.000003
2022-08-12 18:09:56,411 epoch 14 - iter 16940/16949 - loss 0.02446151 - samples/sec: 30.33 - lr: 0.000003
2022-08-12 18:09:57,602 ----------------------------------------------------------------------------------------------------
2022-08-12 18:09:57,602 EPOCH 14 done: loss 0.0245 - lr 0.0000033
2022-08-12 18:56:48,726 DEV : loss 0.3035745322704315 - f1-score (micro avg)  0.9679
2022-08-12 18:56:49,272 BAD EPOCHS (no improvement): 4
2022-08-12 18:56:49,272 ----------------------------------------------------------------------------------------------------
2022-08-12 19:00:34,398 epoch 15 - iter 1694/16949 - loss 0.02109198 - samples/sec: 30.12 - lr: 0.000003
2022-08-12 19:04:26,967 epoch 15 - iter 3388/16949 - loss 0.02093720 - samples/sec: 29.15 - lr: 0.000003
2022-08-12 19:08:10,455 epoch 15 - iter 5082/16949 - loss 0.02103656 - samples/sec: 30.34 - lr: 0.000003
2022-08-12 19:11:54,190 epoch 15 - iter 6776/16949 - loss 0.02093675 - samples/sec: 30.30 - lr: 0.000003
2022-08-12 19:15:35,760 epoch 15 - iter 8470/16949 - loss 0.02115119 - samples/sec: 30.60 - lr: 0.000003
2022-08-12 19:19:20,982 epoch 15 - iter 10164/16949 - loss 0.02148088 - samples/sec: 30.10 - lr: 0.000003
2022-08-12 19:23:05,068 epoch 15 - iter 11858/16949 - loss 0.02195065 - samples/sec: 30.26 - lr: 0.000003
2022-08-12 19:26:46,978 epoch 15 - iter 13552/16949 - loss 0.02207312 - samples/sec: 30.55 - lr: 0.000003
2022-08-12 19:30:31,489 epoch 15 - iter 15246/16949 - loss 0.02209064 - samples/sec: 30.20 - lr: 0.000003
2022-08-12 19:34:24,849 epoch 15 - iter 16940/16949 - loss 0.02238980 - samples/sec: 29.05 - lr: 0.000003
2022-08-12 19:34:26,025 ----------------------------------------------------------------------------------------------------
2022-08-12 19:34:26,026 EPOCH 15 done: loss 0.0224 - lr 0.0000032
2022-08-12 20:22:41,306 DEV : loss 0.323174387216568 - f1-score (micro avg)  0.9682
2022-08-12 20:22:41,840 BAD EPOCHS (no improvement): 4
2022-08-12 20:22:41,841 ----------------------------------------------------------------------------------------------------
2022-08-12 20:26:24,475 epoch 16 - iter 1694/16949 - loss 0.01886736 - samples/sec: 30.45 - lr: 0.000003
2022-08-12 20:30:07,357 epoch 16 - iter 3388/16949 - loss 0.01949222 - samples/sec: 30.42 - lr: 0.000003
2022-08-12 20:33:50,420 epoch 16 - iter 5082/16949 - loss 0.01885202 - samples/sec: 30.40 - lr: 0.000003
2022-08-12 20:37:33,386 epoch 16 - iter 6776/16949 - loss 0.01916309 - samples/sec: 30.41 - lr: 0.000003
2022-08-12 20:41:16,036 epoch 16 - iter 8470/16949 - loss 0.01945985 - samples/sec: 30.45 - lr: 0.000003
2022-08-12 20:44:58,034 epoch 16 - iter 10164/16949 - loss 0.01964669 - samples/sec: 30.54 - lr: 0.000003
2022-08-12 20:48:49,942 epoch 16 - iter 11858/16949 - loss 0.01968085 - samples/sec: 29.24 - lr: 0.000003
2022-08-12 20:52:35,373 epoch 16 - iter 13552/16949 - loss 0.01982121 - samples/sec: 30.08 - lr: 0.000003
2022-08-12 20:56:20,641 epoch 16 - iter 15246/16949 - loss 0.01986327 - samples/sec: 30.10 - lr: 0.000003
2022-08-12 21:00:06,060 epoch 16 - iter 16940/16949 - loss 0.01997019 - samples/sec: 30.08 - lr: 0.000003
2022-08-12 21:00:07,251 ----------------------------------------------------------------------------------------------------
2022-08-12 21:00:07,251 EPOCH 16 done: loss 0.0200 - lr 0.0000030
2022-08-12 21:47:53,140 DEV : loss 0.35329070687294006 - f1-score (micro avg)  0.9677
2022-08-12 21:47:53,688 BAD EPOCHS (no improvement): 4
2022-08-12 21:47:53,688 ----------------------------------------------------------------------------------------------------
2022-08-12 21:51:39,343 epoch 17 - iter 1694/16949 - loss 0.01707117 - samples/sec: 30.05 - lr: 0.000003
2022-08-12 21:55:26,364 epoch 17 - iter 3388/16949 - loss 0.01805828 - samples/sec: 29.87 - lr: 0.000003
2022-08-12 21:59:12,400 epoch 17 - iter 5082/16949 - loss 0.01782019 - samples/sec: 30.00 - lr: 0.000003
2022-08-12 22:02:52,097 epoch 17 - iter 6776/16949 - loss 0.01785877 - samples/sec: 30.86 - lr: 0.000003
2022-08-12 22:06:49,563 epoch 17 - iter 8470/16949 - loss 0.01786626 - samples/sec: 28.55 - lr: 0.000003
2022-08-12 22:10:33,417 epoch 17 - iter 10164/16949 - loss 0.01761319 - samples/sec: 30.29 - lr: 0.000003
2022-08-12 22:14:18,706 epoch 17 - iter 11858/16949 - loss 0.01757407 - samples/sec: 30.10 - lr: 0.000003
2022-08-12 22:18:03,273 epoch 17 - iter 13552/16949 - loss 0.01759422 - samples/sec: 30.19 - lr: 0.000003
2022-08-12 22:21:45,506 epoch 17 - iter 15246/16949 - loss 0.01758182 - samples/sec: 30.51 - lr: 0.000003
2022-08-12 22:25:29,667 epoch 17 - iter 16940/16949 - loss 0.01772588 - samples/sec: 30.25 - lr: 0.000003
2022-08-12 22:25:30,887 ----------------------------------------------------------------------------------------------------
2022-08-12 22:25:30,888 EPOCH 17 done: loss 0.0177 - lr 0.0000029
2022-08-12 23:12:22,347 DEV : loss 0.36815881729125977 - f1-score (micro avg)  0.9678
2022-08-12 23:12:22,863 BAD EPOCHS (no improvement): 4
2022-08-12 23:12:22,864 ----------------------------------------------------------------------------------------------------
2022-08-12 23:16:05,363 epoch 18 - iter 1694/16949 - loss 0.01416093 - samples/sec: 30.47 - lr: 0.000003
2022-08-12 23:19:55,005 epoch 18 - iter 3388/16949 - loss 0.01523929 - samples/sec: 29.52 - lr: 0.000003
2022-08-12 23:23:39,423 epoch 18 - iter 5082/16949 - loss 0.01531162 - samples/sec: 30.21 - lr: 0.000003
2022-08-12 23:27:23,674 epoch 18 - iter 6776/16949 - loss 0.01577745 - samples/sec: 30.23 - lr: 0.000003
2022-08-12 23:31:10,894 epoch 18 - iter 8470/16949 - loss 0.01563973 - samples/sec: 29.84 - lr: 0.000003
2022-08-12 23:34:54,492 epoch 18 - iter 10164/16949 - loss 0.01613399 - samples/sec: 30.32 - lr: 0.000003
2022-08-12 23:38:38,076 epoch 18 - iter 11858/16949 - loss 0.01617723 - samples/sec: 30.32 - lr: 0.000003
2022-08-12 23:42:21,409 epoch 18 - iter 13552/16949 - loss 0.01608131 - samples/sec: 30.36 - lr: 0.000003
2022-08-12 23:46:13,278 epoch 18 - iter 15246/16949 - loss 0.01612396 - samples/sec: 29.24 - lr: 0.000003
2022-08-12 23:50:06,147 epoch 18 - iter 16940/16949 - loss 0.01613841 - samples/sec: 29.11 - lr: 0.000003
2022-08-12 23:50:07,358 ----------------------------------------------------------------------------------------------------
2022-08-12 23:50:07,358 EPOCH 18 done: loss 0.0161 - lr 0.0000027
2022-08-13 00:36:25,583 DEV : loss 0.39001724123954773 - f1-score (micro avg)  0.9676
2022-08-13 00:36:26,079 BAD EPOCHS (no improvement): 4
2022-08-13 00:36:26,080 ----------------------------------------------------------------------------------------------------
2022-08-13 00:40:09,746 epoch 19 - iter 1694/16949 - loss 0.01158168 - samples/sec: 30.32 - lr: 0.000003
2022-08-13 00:43:52,633 epoch 19 - iter 3388/16949 - loss 0.01229603 - samples/sec: 30.42 - lr: 0.000003
2022-08-13 00:47:37,896 epoch 19 - iter 5082/16949 - loss 0.01324307 - samples/sec: 30.10 - lr: 0.000003
2022-08-13 00:51:16,986 epoch 19 - iter 6776/16949 - loss 0.01343540 - samples/sec: 30.95 - lr: 0.000003
2022-08-13 00:55:03,613 epoch 19 - iter 8470/16949 - loss 0.01343670 - samples/sec: 29.92 - lr: 0.000003
2022-08-13 00:58:48,050 epoch 19 - iter 10164/16949 - loss 0.01379875 - samples/sec: 30.21 - lr: 0.000003
2022-08-13 01:02:33,375 epoch 19 - iter 11858/16949 - loss 0.01401854 - samples/sec: 30.09 - lr: 0.000003
2022-08-13 01:06:26,900 epoch 19 - iter 13552/16949 - loss 0.01438200 - samples/sec: 29.03 - lr: 0.000003
2022-08-13 01:10:08,133 epoch 19 - iter 15246/16949 - loss 0.01439121 - samples/sec: 30.65 - lr: 0.000003
2022-08-13 01:13:54,751 epoch 19 - iter 16940/16949 - loss 0.01447177 - samples/sec: 29.92 - lr: 0.000003
2022-08-13 01:13:55,947 ----------------------------------------------------------------------------------------------------
2022-08-13 01:13:55,947 EPOCH 19 done: loss 0.0145 - lr 0.0000025
2022-08-13 02:00:20,846 DEV : loss 0.401226282119751 - f1-score (micro avg)  0.9679
2022-08-13 02:00:21,362 BAD EPOCHS (no improvement): 4
2022-08-13 02:00:21,362 ----------------------------------------------------------------------------------------------------
2022-08-13 02:04:09,037 epoch 20 - iter 1694/16949 - loss 0.01212818 - samples/sec: 29.78 - lr: 0.000003
2022-08-13 02:07:51,818 epoch 20 - iter 3388/16949 - loss 0.01202510 - samples/sec: 30.43 - lr: 0.000003
2022-08-13 02:11:38,197 epoch 20 - iter 5082/16949 - loss 0.01227729 - samples/sec: 29.95 - lr: 0.000002
2022-08-13 02:15:22,564 epoch 20 - iter 6776/16949 - loss 0.01282172 - samples/sec: 30.22 - lr: 0.000002
2022-08-13 02:19:16,657 epoch 20 - iter 8470/16949 - loss 0.01283689 - samples/sec: 28.96 - lr: 0.000002
2022-08-13 02:23:00,397 epoch 20 - iter 10164/16949 - loss 0.01266254 - samples/sec: 30.30 - lr: 0.000002
2022-08-13 02:26:46,532 epoch 20 - iter 11858/16949 - loss 0.01287350 - samples/sec: 29.98 - lr: 0.000002
2022-08-13 02:30:29,838 epoch 20 - iter 13552/16949 - loss 0.01293694 - samples/sec: 30.36 - lr: 0.000002
2022-08-13 02:34:11,601 epoch 20 - iter 15246/16949 - loss 0.01299501 - samples/sec: 30.57 - lr: 0.000002
2022-08-13 02:37:55,102 epoch 20 - iter 16940/16949 - loss 0.01292629 - samples/sec: 30.34 - lr: 0.000002
2022-08-13 02:37:56,279 ----------------------------------------------------------------------------------------------------
2022-08-13 02:37:56,280 EPOCH 20 done: loss 0.0129 - lr 0.0000024
2022-08-13 03:24:42,606 DEV : loss 0.4044613540172577 - f1-score (micro avg)  0.9681
2022-08-13 03:24:43,126 BAD EPOCHS (no improvement): 4
2022-08-13 03:24:43,127 ----------------------------------------------------------------------------------------------------
2022-08-13 03:28:28,906 epoch 21 - iter 1694/16949 - loss 0.01109678 - samples/sec: 30.03 - lr: 0.000002
2022-08-13 03:32:22,041 epoch 21 - iter 3388/16949 - loss 0.01142928 - samples/sec: 29.08 - lr: 0.000002
2022-08-13 03:36:07,471 epoch 21 - iter 5082/16949 - loss 0.01140448 - samples/sec: 30.08 - lr: 0.000002
2022-08-13 03:39:55,664 epoch 21 - iter 6776/16949 - loss 0.01161498 - samples/sec: 29.71 - lr: 0.000002
2022-08-13 03:43:43,157 epoch 21 - iter 8470/16949 - loss 0.01169615 - samples/sec: 29.80 - lr: 0.000002
2022-08-13 03:47:29,656 epoch 21 - iter 10164/16949 - loss 0.01158555 - samples/sec: 29.93 - lr: 0.000002
2022-08-13 03:51:13,313 epoch 21 - iter 11858/16949 - loss 0.01152244 - samples/sec: 30.31 - lr: 0.000002
2022-08-13 03:54:59,315 epoch 21 - iter 13552/16949 - loss 0.01159118 - samples/sec: 30.00 - lr: 0.000002
2022-08-13 03:58:47,027 epoch 21 - iter 15246/16949 - loss 0.01163499 - samples/sec: 29.77 - lr: 0.000002
2022-08-13 04:02:31,550 epoch 21 - iter 16940/16949 - loss 0.01175420 - samples/sec: 30.20 - lr: 0.000002
2022-08-13 04:02:32,919 ----------------------------------------------------------------------------------------------------
2022-08-13 04:02:32,920 EPOCH 21 done: loss 0.0118 - lr 0.0000022
2022-08-13 04:51:44,468 DEV : loss 0.4143857955932617 - f1-score (micro avg)  0.9681
2022-08-13 04:51:45,069 BAD EPOCHS (no improvement): 4
2022-08-13 04:51:45,069 ----------------------------------------------------------------------------------------------------
2022-08-13 04:55:25,581 epoch 22 - iter 1694/16949 - loss 0.01035886 - samples/sec: 30.75 - lr: 0.000002
2022-08-13 04:59:11,848 epoch 22 - iter 3388/16949 - loss 0.00951860 - samples/sec: 29.97 - lr: 0.000002
2022-08-13 05:03:01,388 epoch 22 - iter 5082/16949 - loss 0.01014876 - samples/sec: 29.54 - lr: 0.000002
2022-08-13 05:06:50,246 epoch 22 - iter 6776/16949 - loss 0.01051008 - samples/sec: 29.63 - lr: 0.000002
2022-08-13 05:10:33,703 epoch 22 - iter 8470/16949 - loss 0.01055443 - samples/sec: 30.34 - lr: 0.000002
2022-08-13 05:14:20,710 epoch 22 - iter 10164/16949 - loss 0.01040222 - samples/sec: 29.87 - lr: 0.000002
2022-08-13 05:18:03,390 epoch 22 - iter 11858/16949 - loss 0.01032197 - samples/sec: 30.45 - lr: 0.000002
2022-08-13 05:21:54,236 epoch 22 - iter 13552/16949 - loss 0.01052162 - samples/sec: 29.37 - lr: 0.000002
2022-08-13 05:25:35,304 epoch 22 - iter 15246/16949 - loss 0.01064311 - samples/sec: 30.67 - lr: 0.000002
2022-08-13 05:29:18,156 epoch 22 - iter 16940/16949 - loss 0.01058085 - samples/sec: 30.42 - lr: 0.000002
2022-08-13 05:29:19,308 ----------------------------------------------------------------------------------------------------
2022-08-13 05:29:19,309 EPOCH 22 done: loss 0.0106 - lr 0.0000021
2022-08-13 06:16:31,125 DEV : loss 0.4322650730609894 - f1-score (micro avg)  0.9678
2022-08-13 06:16:31,661 BAD EPOCHS (no improvement): 4
2022-08-13 06:16:31,662 ----------------------------------------------------------------------------------------------------
2022-08-13 06:20:18,495 epoch 23 - iter 1694/16949 - loss 0.01027786 - samples/sec: 29.89 - lr: 0.000002
2022-08-13 06:24:01,230 epoch 23 - iter 3388/16949 - loss 0.01022609 - samples/sec: 30.44 - lr: 0.000002
2022-08-13 06:27:46,904 epoch 23 - iter 5082/16949 - loss 0.00994573 - samples/sec: 30.04 - lr: 0.000002
2022-08-13 06:31:29,017 epoch 23 - iter 6776/16949 - loss 0.01000992 - samples/sec: 30.53 - lr: 0.000002
2022-08-13 06:35:23,591 epoch 23 - iter 8470/16949 - loss 0.00996349 - samples/sec: 28.90 - lr: 0.000002
2022-08-13 06:39:11,595 epoch 23 - iter 10164/16949 - loss 0.00992979 - samples/sec: 29.74 - lr: 0.000002
2022-08-13 06:42:56,576 epoch 23 - iter 11858/16949 - loss 0.00986314 - samples/sec: 30.14 - lr: 0.000002
2022-08-13 06:46:38,968 epoch 23 - iter 13552/16949 - loss 0.00986513 - samples/sec: 30.49 - lr: 0.000002
2022-08-13 06:50:23,537 epoch 23 - iter 15246/16949 - loss 0.00978267 - samples/sec: 30.19 - lr: 0.000002
2022-08-13 06:54:08,216 epoch 23 - iter 16940/16949 - loss 0.00970656 - samples/sec: 30.18 - lr: 0.000002
2022-08-13 06:54:09,436 ----------------------------------------------------------------------------------------------------
2022-08-13 06:54:09,436 EPOCH 23 done: loss 0.0097 - lr 0.0000019
2022-08-13 07:42:29,070 DEV : loss 0.4410195052623749 - f1-score (micro avg)  0.968
2022-08-13 07:42:29,679 BAD EPOCHS (no improvement): 4
2022-08-13 07:42:29,680 ----------------------------------------------------------------------------------------------------
2022-08-13 07:46:15,085 epoch 24 - iter 1694/16949 - loss 0.00790842 - samples/sec: 30.08 - lr: 0.000002
2022-08-13 07:49:59,302 epoch 24 - iter 3388/16949 - loss 0.00814837 - samples/sec: 30.24 - lr: 0.000002
2022-08-13 07:53:52,595 epoch 24 - iter 5082/16949 - loss 0.00813575 - samples/sec: 29.06 - lr: 0.000002
2022-08-13 07:57:36,317 epoch 24 - iter 6776/16949 - loss 0.00800046 - samples/sec: 30.31 - lr: 0.000002
2022-08-13 08:01:21,242 epoch 24 - iter 8470/16949 - loss 0.00812356 - samples/sec: 30.14 - lr: 0.000002
2022-08-13 08:05:04,191 epoch 24 - iter 10164/16949 - loss 0.00833615 - samples/sec: 30.41 - lr: 0.000002
2022-08-13 08:08:50,388 epoch 24 - iter 11858/16949 - loss 0.00831604 - samples/sec: 29.97 - lr: 0.000002
2022-08-13 08:12:39,317 epoch 24 - iter 13552/16949 - loss 0.00841209 - samples/sec: 29.62 - lr: 0.000002
2022-08-13 08:16:22,954 epoch 24 - iter 15246/16949 - loss 0.00845088 - samples/sec: 30.32 - lr: 0.000002
2022-08-13 08:20:04,993 epoch 24 - iter 16940/16949 - loss 0.00869860 - samples/sec: 30.54 - lr: 0.000002
2022-08-13 08:20:06,139 ----------------------------------------------------------------------------------------------------
2022-08-13 08:20:06,140 EPOCH 24 done: loss 0.0087 - lr 0.0000017
2022-08-13 09:10:19,768 DEV : loss 0.44842594861984253 - f1-score (micro avg)  0.9677
2022-08-13 09:10:20,288 BAD EPOCHS (no improvement): 4
2022-08-13 09:10:20,288 ----------------------------------------------------------------------------------------------------
2022-08-13 09:14:02,654 epoch 25 - iter 1694/16949 - loss 0.00866602 - samples/sec: 30.49 - lr: 0.000002
2022-08-13 09:17:44,596 epoch 25 - iter 3388/16949 - loss 0.00805383 - samples/sec: 30.55 - lr: 0.000002
2022-08-13 09:21:29,500 epoch 25 - iter 5082/16949 - loss 0.00824129 - samples/sec: 30.15 - lr: 0.000002
2022-08-13 09:25:14,793 epoch 25 - iter 6776/16949 - loss 0.00814791 - samples/sec: 30.09 - lr: 0.000002
2022-08-13 09:28:58,376 epoch 25 - iter 8470/16949 - loss 0.00828762 - samples/sec: 30.32 - lr: 0.000002
2022-08-13 09:32:39,509 epoch 25 - iter 10164/16949 - loss 0.00827375 - samples/sec: 30.66 - lr: 0.000002
2022-08-13 09:36:20,723 epoch 25 - iter 11858/16949 - loss 0.00830681 - samples/sec: 30.65 - lr: 0.000002
2022-08-13 09:40:14,628 epoch 25 - iter 13552/16949 - loss 0.00817202 - samples/sec: 28.99 - lr: 0.000002
2022-08-13 09:43:58,974 epoch 25 - iter 15246/16949 - loss 0.00820075 - samples/sec: 30.22 - lr: 0.000002
2022-08-13 09:47:41,547 epoch 25 - iter 16940/16949 - loss 0.00822061 - samples/sec: 30.46 - lr: 0.000002
2022-08-13 09:47:42,928 ----------------------------------------------------------------------------------------------------
2022-08-13 09:47:42,928 EPOCH 25 done: loss 0.0082 - lr 0.0000016
2022-08-13 10:34:16,161 DEV : loss 0.46217408776283264 - f1-score (micro avg)  0.9676
2022-08-13 10:34:16,677 BAD EPOCHS (no improvement): 4
2022-08-13 10:34:16,677 ----------------------------------------------------------------------------------------------------
2022-08-13 10:37:59,635 epoch 26 - iter 1694/16949 - loss 0.00752277 - samples/sec: 30.41 - lr: 0.000002
2022-08-13 10:41:43,833 epoch 26 - iter 3388/16949 - loss 0.00837427 - samples/sec: 30.24 - lr: 0.000002
2022-08-13 10:45:27,675 epoch 26 - iter 5082/16949 - loss 0.00839296 - samples/sec: 30.29 - lr: 0.000002
2022-08-13 10:49:10,860 epoch 26 - iter 6776/16949 - loss 0.00818580 - samples/sec: 30.38 - lr: 0.000002
2022-08-13 10:53:01,321 epoch 26 - iter 8470/16949 - loss 0.00804422 - samples/sec: 29.42 - lr: 0.000002
2022-08-13 10:56:55,164 epoch 26 - iter 10164/16949 - loss 0.00819614 - samples/sec: 28.99 - lr: 0.000001
2022-08-13 11:00:41,389 epoch 26 - iter 11858/16949 - loss 0.00808251 - samples/sec: 29.97 - lr: 0.000001
2022-08-13 11:04:22,481 epoch 26 - iter 13552/16949 - loss 0.00805966 - samples/sec: 30.67 - lr: 0.000001
2022-08-13 11:08:07,787 epoch 26 - iter 15246/16949 - loss 0.00791610 - samples/sec: 30.09 - lr: 0.000001
2022-08-13 11:11:50,835 epoch 26 - iter 16940/16949 - loss 0.00783380 - samples/sec: 30.40 - lr: 0.000001
2022-08-13 11:11:52,185 ----------------------------------------------------------------------------------------------------
2022-08-13 11:11:52,186 EPOCH 26 done: loss 0.0078 - lr 0.0000014
2022-08-13 11:58:58,905 DEV : loss 0.4614032506942749 - f1-score (micro avg)  0.9679
2022-08-13 11:58:59,468 BAD EPOCHS (no improvement): 4
2022-08-13 11:58:59,468 ----------------------------------------------------------------------------------------------------
2022-08-13 12:02:45,723 epoch 27 - iter 1694/16949 - loss 0.00677990 - samples/sec: 29.97 - lr: 0.000001
2022-08-13 12:06:30,665 epoch 27 - iter 3388/16949 - loss 0.00723031 - samples/sec: 30.14 - lr: 0.000001
2022-08-13 12:10:25,281 epoch 27 - iter 5082/16949 - loss 0.00743326 - samples/sec: 28.90 - lr: 0.000001
2022-08-13 12:14:04,018 epoch 27 - iter 6776/16949 - loss 0.00730360 - samples/sec: 31.00 - lr: 0.000001
2022-08-13 12:17:49,589 epoch 27 - iter 8470/16949 - loss 0.00729370 - samples/sec: 30.06 - lr: 0.000001
2022-08-13 12:21:31,140 epoch 27 - iter 10164/16949 - loss 0.00702423 - samples/sec: 30.60 - lr: 0.000001
2022-08-13 12:25:15,246 epoch 27 - iter 11858/16949 - loss 0.00704516 - samples/sec: 30.25 - lr: 0.000001
2022-08-13 12:28:56,163 epoch 27 - iter 13552/16949 - loss 0.00714172 - samples/sec: 30.69 - lr: 0.000001
2022-08-13 12:32:37,511 epoch 27 - iter 15246/16949 - loss 0.00713699 - samples/sec: 30.63 - lr: 0.000001
2022-08-13 12:36:23,140 epoch 27 - iter 16940/16949 - loss 0.00716713 - samples/sec: 30.05 - lr: 0.000001
2022-08-13 12:36:24,382 ----------------------------------------------------------------------------------------------------
2022-08-13 12:36:24,383 EPOCH 27 done: loss 0.0072 - lr 0.0000013
2022-08-13 13:21:48,592 DEV : loss 0.476126104593277 - f1-score (micro avg)  0.9676
2022-08-13 13:21:49,186 BAD EPOCHS (no improvement): 4
2022-08-13 13:21:49,186 ----------------------------------------------------------------------------------------------------
2022-08-13 13:25:38,659 epoch 28 - iter 1694/16949 - loss 0.00575842 - samples/sec: 29.55 - lr: 0.000001
2022-08-13 13:29:27,357 epoch 28 - iter 3388/16949 - loss 0.00624237 - samples/sec: 29.65 - lr: 0.000001
2022-08-13 13:33:15,048 epoch 28 - iter 5082/16949 - loss 0.00668054 - samples/sec: 29.78 - lr: 0.000001
2022-08-13 13:37:02,416 epoch 28 - iter 6776/16949 - loss 0.00646777 - samples/sec: 29.82 - lr: 0.000001
2022-08-13 13:40:49,461 epoch 28 - iter 8470/16949 - loss 0.00653444 - samples/sec: 29.86 - lr: 0.000001
2022-08-13 13:44:36,445 epoch 28 - iter 10164/16949 - loss 0.00644683 - samples/sec: 29.87 - lr: 0.000001
2022-08-13 13:48:22,352 epoch 28 - iter 11858/16949 - loss 0.00643552 - samples/sec: 30.01 - lr: 0.000001
2022-08-13 13:52:07,932 epoch 28 - iter 13552/16949 - loss 0.00646237 - samples/sec: 30.06 - lr: 0.000001
2022-08-13 13:56:03,802 epoch 28 - iter 15246/16949 - loss 0.00636921 - samples/sec: 28.74 - lr: 0.000001
2022-08-13 13:59:46,174 epoch 28 - iter 16940/16949 - loss 0.00646497 - samples/sec: 30.49 - lr: 0.000001
2022-08-13 13:59:47,403 ----------------------------------------------------------------------------------------------------
2022-08-13 13:59:47,404 EPOCH 28 done: loss 0.0065 - lr 0.0000011
2022-08-13 14:45:07,846 DEV : loss 0.4761736989021301 - f1-score (micro avg)  0.9678
2022-08-13 14:45:08,384 BAD EPOCHS (no improvement): 4
2022-08-13 14:45:08,385 ----------------------------------------------------------------------------------------------------
2022-08-13 14:48:50,449 epoch 29 - iter 1694/16949 - loss 0.00558111 - samples/sec: 30.53 - lr: 0.000001
2022-08-13 14:52:32,400 epoch 29 - iter 3388/16949 - loss 0.00602626 - samples/sec: 30.55 - lr: 0.000001
2022-08-13 14:56:15,512 epoch 29 - iter 5082/16949 - loss 0.00577411 - samples/sec: 30.39 - lr: 0.000001
2022-08-13 14:59:59,934 epoch 29 - iter 6776/16949 - loss 0.00566507 - samples/sec: 30.21 - lr: 0.000001
2022-08-13 15:03:49,403 epoch 29 - iter 8470/16949 - loss 0.00601331 - samples/sec: 29.55 - lr: 0.000001
2022-08-13 15:07:46,254 epoch 29 - iter 10164/16949 - loss 0.00598128 - samples/sec: 28.63 - lr: 0.000001
2022-08-13 15:11:29,182 epoch 29 - iter 11858/16949 - loss 0.00590727 - samples/sec: 30.41 - lr: 0.000001
2022-08-13 15:15:18,243 epoch 29 - iter 13552/16949 - loss 0.00593813 - samples/sec: 29.60 - lr: 0.000001
2022-08-13 15:19:01,436 epoch 29 - iter 15246/16949 - loss 0.00592604 - samples/sec: 30.38 - lr: 0.000001
2022-08-13 15:22:42,849 epoch 29 - iter 16940/16949 - loss 0.00587405 - samples/sec: 30.62 - lr: 0.000001
2022-08-13 15:22:44,076 ----------------------------------------------------------------------------------------------------
2022-08-13 15:22:44,076 EPOCH 29 done: loss 0.0059 - lr 0.0000010
2022-08-13 16:08:19,772 DEV : loss 0.48071756958961487 - f1-score (micro avg)  0.9681
2022-08-13 16:08:20,333 BAD EPOCHS (no improvement): 4
2022-08-13 16:08:20,334 ----------------------------------------------------------------------------------------------------
2022-08-13 16:12:03,533 epoch 30 - iter 1694/16949 - loss 0.00661047 - samples/sec: 30.38 - lr: 0.000001
2022-08-13 16:15:51,657 epoch 30 - iter 3388/16949 - loss 0.00627094 - samples/sec: 29.72 - lr: 0.000001
2022-08-13 16:19:44,749 epoch 30 - iter 5082/16949 - loss 0.00589563 - samples/sec: 29.09 - lr: 0.000001
2022-08-13 16:23:30,398 epoch 30 - iter 6776/16949 - loss 0.00585512 - samples/sec: 30.05 - lr: 0.000001
2022-08-13 16:27:15,526 epoch 30 - iter 8470/16949 - loss 0.00572125 - samples/sec: 30.12 - lr: 0.000001
2022-08-13 16:30:59,590 epoch 30 - iter 10164/16949 - loss 0.00596785 - samples/sec: 30.26 - lr: 0.000001
2022-08-13 16:34:45,167 epoch 30 - iter 11858/16949 - loss 0.00598933 - samples/sec: 30.06 - lr: 0.000001
2022-08-13 16:38:28,009 epoch 30 - iter 13552/16949 - loss 0.00602857 - samples/sec: 30.43 - lr: 0.000001
2022-08-13 16:42:13,393 epoch 30 - iter 15246/16949 - loss 0.00589979 - samples/sec: 30.08 - lr: 0.000001
2022-08-13 16:45:57,850 epoch 30 - iter 16940/16949 - loss 0.00579923 - samples/sec: 30.21 - lr: 0.000001
2022-08-13 16:45:59,115 ----------------------------------------------------------------------------------------------------
2022-08-13 16:45:59,116 EPOCH 30 done: loss 0.0058 - lr 0.0000008
2022-08-13 16:47:32,744 ----------------------------------------------------------------------------------------------------
2022-08-13 16:47:32,745 Exiting from training early.
2022-08-13 16:47:32,745 Saving model ...
2022-08-13 16:47:34,065 Done.
2022-08-13 16:47:34,096 ----------------------------------------------------------------------------------------------------
2022-08-13 16:47:34,098 Testing using last state of model ...
